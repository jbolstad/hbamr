% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/hbam.R
\name{hbam}
\alias{hbam}
\title{Fit an HBAM model}
\usage{
hbam(
  self = NULL,
  stimuli = NULL,
  model = "HBAM",
  allow_miss = 2,
  req_valid = NA,
  req_unique = 2,
  prefs = NULL,
  prep_data = TRUE,
  data = NULL,
  chains = 4,
  cores = min(parallel::detectCores(logical = FALSE), chains, 6),
  warmup = 1000,
  iter = 4000,
  thin = 3,
  control = list(adapt_delta = 0.6),
  ...
)
}
\arguments{
\item{self}{A numerical vector of N ideological self-placements. Any missing data must be coded as NA. This argument will not be used if the data have been prepared in advance via the \code{prep_data} function.}

\item{stimuli}{An N Ã— J matrix of numerical stimulus placements, where J is the number of stimuli. Any missing data must be coded as NA. This argument will not be used if the data have been prepared in advance via the \code{prep_data} function.}

\item{model}{Character: Name of the model to be used. One of: \code{"HBAM"}, \code{"HBAM_2"}, \code{"HBAM_0"}, \code{"HBAM_R"}, or \code{"BAM"}. Defaults to \code{"HBAM"}.}

\item{allow_miss}{Integer specifying how many missing stimulus positions to be accepted for an individual still to be included in the analysis. This argument will not be used if the data have been prepared in advance via the \code{prep_data} function. Defaults to 2.}

\item{req_valid}{Integer specifying how many valid observations to require for a respondent to be included in the analysis. The default is \code{req_valid = J - allow_miss}, but if specified, \code{req_valid} takes precedence. This argument will not be used if the data have been prepared in advance via the \code{prep_data} function.}

\item{req_unique}{Integer specifying how may unique positions on the ideological scale each respondent is required to have used when placing the stimuli in order to be included in the analysis. The default is \code{req_unique = 2}. This argument will not be used if the data have been prepared in advance via the \code{prep_data} function.}

\item{prep_data}{Logical: Should the data be prepared before fitting the model? (Or have the data been prepared in advance via the \code{prep_data} function? If so, set \code{prep_data = FALSE}.)}

\item{data}{List of data that have been prepared in advance via the \code{prep_data} function. Only applicable when \code{prep_data = TRUE}.}

\item{chains}{A positive integer specifying the number of Markov chains. Defaults to 4.}

\item{cores}{The number of cores to use when executing the Markov chains in parallel. Defaults to \code{min(parallel::detectCores(logical = FALSE), chains, 6)}.}

\item{warmup}{A positive integer specifying the number of warmup (aka burn-in) iterations per chain. If step-size adaptation is on (which it is by default), this also controls the number of iterations for which adaptation is run (and hence these warmup samples should not be used for inference). The number of warmup iterations should be smaller than \code{iter}.}

\item{iter}{A positive integer specifying the number of iterations for each chain (including warmup).}

\item{thin}{A positive integer specifying the period for saving samples.}

\item{...}{Arguments passed to \code{rstan::sampling}.}
}
\value{
An object of S4 class \code{stanfit}.
}
\description{
Fit a Hierarchical Bayesian Aldrich-McKelvey model using automatically tuned Hamiltonian Monte Carlo (NUTS) sampling via \code{rstan}.
}
\examples{

# Loading and recoding data
data(LC1980)
dat <- LC1980
dat[dat == 0 | dat == 8 | dat == 9] <- NA
self <- dat[, 1]
stimuli <- dat[, -1]

# Fitting the standard HBAM model, using default settings:
fit_hbam <- hbam(self, stimuli)

# Preparing data in advance, using defaults:
dat <- prep_data(self, stimuli)
fit_hbam <- hbam(data = dat, prep_data = FALSE)
}
