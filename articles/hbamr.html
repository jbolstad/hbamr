<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="hbamr">
<title>Hierarchical Bayesian Aldrich-McKelvey Scaling in R via Stan • hbamr</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Hierarchical Bayesian Aldrich-McKelvey Scaling in R via Stan">
<meta property="og:description" content="hbamr">
<meta property="og:image" content="https://jbolstad.github.io/hbamr/logo.png">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">hbamr</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="Released version">2.1.1</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="active nav-item">
  <a class="nav-link" href="../articles/hbamr.html">Get started</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../news/index.html">Changelog</a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/jbolstad/hbamr/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Hierarchical Bayesian Aldrich-McKelvey Scaling in R via Stan</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/jbolstad/hbamr/blob/HEAD/vignettes/hbamr.Rmd" class="external-link"><code>vignettes/hbamr.Rmd</code></a></small>
      <div class="d-none name"><code>hbamr.Rmd</code></div>
    </div>

    
    
<!-- avoid border around images -->
<style> img { border: 0; } </style>
<p>The goal of the <strong>hbamr</strong> package is to enable users to
efficiently perform Hierarchical Bayesian Aldrich-McKelvey (HBAM)
scaling in R. Aldrich-McKelvey (AM) scaling is a method for estimating
the ideological positions of survey respondents and political actors on
a common scale using ideological survey data <span class="citation">(Aldrich and McKelvey 1977)</span>. The hierarchical
versions of the AM model included in this package outperform other
versions both in terms of yielding meaningful posterior distributions
for all respondent positions and in terms of recovering true respondent
positions in simulations. The original version of the default model is
described in an <a href="https://doi.org/10.1017/pan.2023.18" class="external-link">open
access article</a> <span class="citation">(Bølstad 2024)</span>.</p>
<p>The package mainly fits models via the NUTS algorithm in
<strong>rstan</strong> – a Markov chain Monte Carlo (MCMC) algorithm.
However, it also offers a simplified model that can be fit using
optimization to analyze large data sets quickly.</p>
<p>This vignette provides an overview of how to use the key functions in
the <strong>hbamr</strong> package. The vignette walks through an
applied example, showing how to prepare data, fit models, extract
estimates, plot key results, and perform cross-validation.</p>
<div class="section level2">
<h2 id="example-data">Example Data<a class="anchor" aria-label="anchor" href="#example-data"></a>
</h2>
<p>For illustration, we will use data from the 1980 American National
Election Study (ANES). This is the same data set that serves to
illustrate the original AM model in the <strong>basicspace</strong>
package. The data set is included in the <strong>hbamr</strong> package
and can be loaded by running <code>data(LC1980)</code>.</p>
<p>The data set contains respondents’ placements of themselves and six
stimuli on 7-point Liberal-Conservative scales. The stimuli in question
are: The Democratic and Republican parties, Democratic presidential
candidate Jimmy Carter, Republican candidate Ronald Reagan, independent
candidate (and former Republican) John B. Anderson, and Ted Kennedy (who
challenged the incumbent Carter, but failed to win the Democratic
nomination).</p>
<p>We load the data and re-code missing values as follows:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="st"><a href="https://jbolstad.github.io/hbamr/">"hbamr"</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="va">LC1980</span><span class="op">)</span></span>
<span><span class="va">LC1980</span><span class="op">[</span><span class="va">LC1980</span> <span class="op">==</span> <span class="fl">0</span> <span class="op">|</span> <span class="va">LC1980</span> <span class="op">==</span> <span class="fl">8</span> <span class="op">|</span> <span class="va">LC1980</span> <span class="op">==</span> <span class="fl">9</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="cn">NA</span> </span>
<span><span class="va">self</span> <span class="op">&lt;-</span> <span class="va">LC1980</span><span class="op">[</span>, <span class="fl">1</span><span class="op">]</span></span>
<span><span class="va">stimuli</span> <span class="op">&lt;-</span> <span class="va">LC1980</span><span class="op">[</span>, <span class="op">-</span><span class="fl">1</span><span class="op">]</span></span></code></pre></div>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">stimuli</span><span class="op">)</span> </span></code></pre></div>
<pre><code><span><span class="co">##    Carter Reagan Kennedy Anderson Republicans Democrats</span></span>
<span><span class="co">## 1       2      6       1        7           5         5</span></span>
<span><span class="co">## 8       4      6       4        7           6         4</span></span>
<span><span class="co">## 9       3      6       3        3           6         2</span></span>
<span><span class="co">## 10      6      4       3        3           5         4</span></span>
<span><span class="co">## 11      7      2       5        5           7         5</span></span>
<span><span class="co">## 13      6      6       2        5           7         4</span></span></code></pre>
</div>
<div class="section level2">
<h2 id="preparing-the-data">Preparing the Data<a class="anchor" aria-label="anchor" href="#preparing-the-data"></a>
</h2>
<p>The function <code><a href="../reference/prep_data.html">prep_data()</a></code> serves to prepare the data.
This function can be run ahead of fitting the models, or it can be run
implicitly as part of a single function call to fit the models (as shown
below). The function takes a vector of <span class="math inline">\(N\)</span> ideological self-placements and an
<span class="math inline">\(N \times J\)</span> matrix of stimulus
placements. It applies a set of inclusion criteria, performs any
necessary data transformation, and returns a list of data suited for
sampling in <strong>rstan</strong>. The stimuli data are stored in a
vector as a long-form sparse matrix. If the stimuli data include
column-names, these will be preserved for later use.</p>
<p>Any missing data must be set to <code>NA</code> before use. The
<code><a href="../reference/prep_data.html">prep_data()</a></code> function allows the user to decide how many
missing values should be permitted per respondent by specifying the
argument <code>allow_miss</code>. (The default is
<code>allow_miss = 2</code>. Alternatively, the argument
<code>req_valid</code> specifies how many valid observations to require
per respondent. The default is <code>req_valid = J - allow_miss</code>,
but, if specified, <code>req_valid</code> takes precedence.) Similarly,
the user may specify how may unique positions on the ideological scale
each respondent is required to have used when placing the stimuli in
order to be included in the analysis. The default is
<code>req_unique = 2</code>, which means that respondents who place all
stimuli in exactly the same place will not be included.</p>
<p>The data provided to <code><a href="../reference/prep_data.html">prep_data()</a></code> can be centered, but
they do not have to be: The function will detect un-centered data and
attempt to center these automatically, assuming that the highest and
lowest observed values in the data mark the extremes of the scale.</p>
<p>To use the <code><a href="../reference/prep_data.html">prep_data()</a></code> function on the example data
using the default settings, we would run:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/prep_data.html">prep_data</a></span><span class="op">(</span><span class="va">self</span>, <span class="va">stimuli</span><span class="op">)</span></span></code></pre></div>
<p>Users who want to keep other covariates for subsequent analysis, may
find it useful to run <code><a href="../reference/prep_data.html">prep_data()</a></code> separately from the call
to fit the models. The list returned by this function includes the
logical vector <code>keep</code>, which identifies the rows in the
original data that have been kept. If we had a data set <code>x</code>
containing covariates, and used <code><a href="../reference/prep_data.html">prep_data()</a></code> to produce the
list <code>dat</code>, then we could use <code>x[dat$keep, ]</code> to
get a subset of <code>x</code> corresponding to the data used in the
analysis. (The order of the individuals/rows in the data remains
unchanged by the functions in this package.)</p>
</div>
<div class="section level2">
<h2 id="models">Models<a class="anchor" aria-label="anchor" href="#models"></a>
</h2>
<p>This package provides several alternative models that can be selected
using the names below. Users who are unsure which model to use are
advised to use the default HBAM model. If speed or sampling diagnostics
are an issue, HBAM_MINI may provide a useful alternative. (See also the
section on cross-validation for further discussion on the issue of model
selection.)</p>
<p><strong>HBAM</strong> is the default model, which allows for scale
flipping and employs hierarchical priors on the shift and stretch
parameters. It also models heteroskedastic errors that vary by both
individual and stimuli. Compared to the model in <span class="citation">Bølstad (2024)</span>, this version has been slightly
revised to provide faster sampling. A key difference from the original
model is that the respondent positions are not treated as parameters,
but rather calculated as a function of self-placements, individual-level
parameters, and simulated errors. This makes the model considerably
faster, while yielding very similar results. The model simulates errors
in the self-placements of the same magnitude as that with which the
respondent in question places the stimulus with the smallest errors. All
models in the package use this approach.</p>
<p><strong>HBAM_MULTI</strong> is a version that models differences
between groups defined by the user. It requires an integer vector
identifying the groups to be supplied as the argument
<code>group_id</code>. The model gives each group separate
hyperparameters for the locations of the prior distributions for the
shift and stretch parameters. Rather than shrinking the estimates toward
the mode for the whole dataset, this model shrinks the estimates toward
the mode for the group. The vectors of hyperparameters are called
<code>mu_alpha</code> and <code>mu_beta</code> and are constructed to
have means of 0. The scales of the priors on these hyperparameters can
be set by the user via the arguments <code>sigma_mu_alpha</code> and
<code>sigma_mu_beta</code>. The default values are B / 5 and .3,
respectively. (Here, B measures the length of the survey scale as the
number of possible placements on one side of the center.) One potential
use for this model is to supply self-placements (appropriately
transformed) as <code>group_id</code>, and thus give each self-placement
group its own prior distribution for the shift and stretch
parameters.</p>
<p><strong>HBAM_NF</strong> (formerly HBAM_0) is a version of the HBAM
model that does not allow for scale flipping. This may be useful if
there are truly zero cases of scale flipping in the data. Such scenarios
can be created artificially, but may also arise in real data. For
example, expert surveys appear unlikely to contain many instances of
scale flipping. For data that contain zero cases of flipping, models
that allow for flipping contain superfluous parameters that lead to
inefficient sampling. Models that do not allow for flipping will sample
faster and typically yield slightly more accurate estimates. Such models
are therefore preferable when no flipping is present.</p>
<p><strong>HBAM_MULTI_NF</strong> is a version of the HBAM_MULTI model
that does not allow for scale flipping.</p>
<p><strong>HBAM_MINI</strong> is a version of the HBAM model that
assumes the prediction errors in the stimuli placements to be
homoskedastic. This model tends to sample faster faster than the
standard HBAM model while yielding very similar point estimates. For
large datasets, this model may provide a reasonable compromise between
model complexity and estimation speed.</p>
<p><strong>FBAM_MINI</strong> is a version of the HBAM_MINI model with
fixed hyperparameters to allow fitting via optimization rather than MCMC
– which can be useful for large data sets. This model allows the user to
specify the scales of the priors for the shift and (logged) stretch
parameters via the arguments <code>sigma_alpha</code> and
<code>sigma_beta</code>. The default values are B / 4 and .35,
respectively. These defaults are intended to be realistic and weakly
informative. Users who want to control the degree of shrinkage of the
individual-level parameters may find it useful to fit this model – or
other FBAM models – via either MCMC or optimization.</p>
<p><strong>FBAM_MULTI</strong> is a version of the FBAM_MINI model that
shares the group-modeling features of the HBAM_MULTI model. It allows
the user to set the scales of the priors for the shift and stretch
parameters via the arguments <code>sigma_alpha</code> and
<code>sigma_beta</code>, and set the scales of the priors on
<code>mu_alpha</code> and <code>mu_beta</code> via the arguments
<code>sigma_mu_alpha</code> and <code>sigma_mu_beta</code>.</p>
<p><strong>FBAM_MULTI_NF</strong> is a version of the FBAM_MULTI model
that does not allow for scale flipping.</p>
<p><strong>HBAM_R_MINI</strong> is a version of the HBAM_MINI model that
incorporates the rationalization component of the ISR model in <span class="citation">Bølstad (2020)</span>. This model requires additional
data to be supplied as the argument <code>pref</code>: An N × J matrix
of stimuli ratings from the respondents. The rationalization part of the
model is simplified relative to the original ISR model: The direction in
which respondents move disfavored stimuli is estimated as a common
expectation for each possible self-placement on the scale.</p>
<p><strong>BAM</strong> is an unpooled model with wide uniform priors on
the shift and stretch parameters. It is similar to the JAGS version
introduced by <span class="citation">Hare et al. (2015)</span>. This
model is mainly provided to offer a baseline for model comparisons.
While it is simple and fast, this model tends to overfit the data and
produce invalid posterior distributions for some respondent positions
<span class="citation">(Bølstad 2024)</span>.</p>
<p><strong>HBAM_2</strong> has been replaced by the more general
HBAM_MULTI model.</p>
<p>These models can also be used in situations where self-placements are
not available and the only goal is to estimate stimulus positions. This
can be achieved by supplying a vector of zeros (or random data) instead
of real self-placements: <code>self = rep(0, nrow(stimuli))</code>.</p>
<p>To see the Stan code for any of the models, use the
<code><a href="../reference/show_code.html">show_code()</a></code> function:</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/show_code.html">show_code</a></span><span class="op">(</span><span class="st">"HBAM_MULTI"</span><span class="op">)</span></span></code></pre></div>
<div class="section level3">
<h3 id="summary-of-model-features">Summary of Model Features<a class="anchor" aria-label="anchor" href="#summary-of-model-features"></a>
</h3>
<table class="table">
<caption>Recommended models for fitting via MCMC</caption>
<colgroup>
<col width="29%">
<col width="14%">
<col width="14%">
<col width="14%">
<col width="14%">
<col width="14%">
</colgroup>
<thead><tr class="header">
<th></th>
<th align="center">HBAM<br> </th>
<th align="center">HBAM<br>MULTI</th>
<th align="center">HBAM<br>NF</th>
<th align="center">HBAM<br>MULTI_NF</th>
<th align="center">HBAM<br>MINI</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Hierarchical priors</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
</tr>
<tr class="even">
<td>Scale flipping</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
<td align="center">X</td>
</tr>
<tr class="odd">
<td>Group-differences</td>
<td align="center"></td>
<td align="center">X</td>
<td align="center"></td>
<td align="center">X</td>
<td align="center"></td>
</tr>
<tr class="even">
<td>Heteroskedastic errors</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
</tr>
</tbody>
</table>
<table class="table">
<caption>Non-hierarchical and special purpose models (“*” marks optional
features)</caption>
<colgroup>
<col width="29%">
<col width="14%">
<col width="14%">
<col width="14%">
<col width="14%">
<col width="14%">
</colgroup>
<thead><tr class="header">
<th></th>
<th align="center">FBAM<br>MINI</th>
<th align="center">FBAM<br>MULTI</th>
<th align="center">FBAM<br>MULTI_NF</th>
<th align="center">HBAM<br>R_MINI</th>
<th align="center">BAM<br> </th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Hierarchical priors</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center">X</td>
<td align="center"></td>
</tr>
<tr class="even">
<td>User-defined priors*</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="odd">
<td>Scale flipping</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center">X</td>
<td align="center">X</td>
</tr>
<tr class="even">
<td>Group-differences</td>
<td align="center"></td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="odd">
<td>Heteroskedastic errors</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center">X</td>
</tr>
<tr class="even">
<td>Rationalization</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center">X</td>
<td align="center"></td>
</tr>
<tr class="odd">
<td>Fitting via optimization*</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center">X</td>
<td align="center"></td>
<td align="center"></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section level2">
<h2 id="fitting">Fitting<a class="anchor" aria-label="anchor" href="#fitting"></a>
</h2>
<p>The <code><a href="../reference/hbam.html">hbam()</a></code> function can be used to fit all models in
this package and it returns a <code>stanfit</code> object. The default
model is HBAM, while other models can be specified via the argument
<code>model</code>. For each model, <code><a href="../reference/hbam.html">hbam()</a></code> selects a
suitable function to produce initial values for the sampling
algorithm.</p>
<p>Unless the user supplies pre-prepared data via the
<code>data</code>-argument, <code><a href="../reference/hbam.html">hbam()</a></code> will implicitly run
<code><a href="../reference/prep_data.html">prep_data()</a></code>. It therefore takes the same arguments as the
<code><a href="../reference/prep_data.html">prep_data()</a></code> function (i.e. <code>self</code>,
<code>stimuli</code>, <code>allow_miss</code>, <code>req_valid</code>,
and <code>req_unique</code>).</p>
<p>To fit the HBAM model using the default settings, we would run:</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_hbam</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/hbam.html">hbam</a></span><span class="op">(</span><span class="va">self</span>, <span class="va">stimuli</span><span class="op">)</span></span></code></pre></div>
<p>To fit the HBAM_MINI model while requiring complete data for all
respondents, we would run:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_hbam_mini</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/hbam.html">hbam</a></span><span class="op">(</span><span class="va">self</span>, <span class="va">stimuli</span>, model <span class="op">=</span> <span class="st">"HBAM_MINI"</span>, allow_miss <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span></code></pre></div>
<p>If we wanted to run the <code><a href="../reference/prep_data.html">prep_data()</a></code> function separately
before fitting the model, we would supply output from
<code><a href="../reference/prep_data.html">prep_data()</a></code> as the argument <code>data</code>:</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/prep_data.html">prep_data</a></span><span class="op">(</span><span class="va">self</span>, <span class="va">stimuli</span>, allow_miss <span class="op">=</span> <span class="fl">0</span><span class="op">)</span> </span>
<span><span class="va">fit_hbam</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/hbam.html">hbam</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">dat</span><span class="op">)</span></span></code></pre></div>
<p>To fit the HBAM_MULTI or FBAM_MULTI model, we would need to supply a
vector identifying the groups of interest. One option would be to give
each self-placement group their own prior distributions for the shift
and stretch parameters. (Note that supplying the raw self-placements as
<code>group_id</code> works in this case because the self-placements are
stored as positive integers from 1 to 7 – otherwise they would have to
be re-coded.) If we decided to fit the FBAM_MULTI model, we could also
specify our own scales for the priors on key parameters:</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_fbam_multi</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/hbam.html">hbam</a></span><span class="op">(</span><span class="va">self</span>, <span class="va">stimuli</span>, model <span class="op">=</span> <span class="st">"FBAM_MULTI"</span>, group_id <span class="op">=</span> <span class="va">self</span>, </span>
<span>                       sigma_alpha <span class="op">=</span> <span class="fl">.8</span>, sigma_mu_alpha <span class="op">=</span> <span class="fl">.5</span>, </span>
<span>                       sigma_beta <span class="op">=</span> <span class="fl">.4</span>, sigma_mu_beta <span class="op">=</span> <span class="fl">.25</span><span class="op">)</span></span></code></pre></div>
<p><code><a href="../reference/hbam.html">hbam()</a></code> uses <code><a href="https://mc-stan.org/rstan/reference/stanmodel-method-sampling.html" class="external-link">rstan::sampling()</a></code>, and any
additional arguments to <code><a href="../reference/hbam.html">hbam()</a></code> will be passed on to the
sampling function. By default, <code><a href="../reference/hbam.html">hbam()</a></code> will run 4 chains and
detect the number of available CPU cores. If possible,
<code><a href="../reference/hbam.html">hbam()</a></code> will use as many cores as there are chains. The
other sampling defaults are: <code>warmup = 1000</code> and
<code>iter = 2000</code>. These settings can all be overridden in the
<code><a href="../reference/hbam.html">hbam()</a></code> call.</p>
<div class="section level3">
<h3 id="fitting-via-optimization">Fitting via Optimization<a class="anchor" aria-label="anchor" href="#fitting-via-optimization"></a>
</h3>
<p>For very large data sets, optimization can be a useful and much
faster alternative to MCMC. However, the optimization feature provided
in this package only provides maximum a posteriori (MAP) point
estimates.</p>
<p>The <code><a href="../reference/fbam.html">fbam()</a></code> function fits FBAM models using
<code><a href="https://mc-stan.org/rstan/reference/stanmodel-method-optimizing.html" class="external-link">rstan::optimizing()</a></code>. The <code><a href="../reference/fbam.html">fbam()</a></code> function works
just like the <code><a href="../reference/hbam.html">hbam()</a></code> function, except the arguments for
<code><a href="https://mc-stan.org/rstan/reference/stanmodel-method-sampling.html" class="external-link">rstan::sampling()</a></code> do not apply. To fit the FBAM_MINI model
using default settings, we would run:</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_fbam</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/fbam.html">fbam</a></span><span class="op">(</span><span class="va">self</span>, <span class="va">stimuli</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="execution-times">Execution Times<a class="anchor" aria-label="anchor" href="#execution-times"></a>
</h3>
<p>Models of the kind included in the <strong>hbamr</strong> package
face an inevitable trade-off between nuance (i.e. model complexity) and
execution times. For small data sets (like ANES 1980), all models
provide reasonable running times, but for large data sets (like ANES
2012), more complex models tend to get slow. In these cases, the
HBAM_MINI model may be a useful alternative. For very large data sets,
fitting the FBAM_MINI model via optimization may be the best
alternative.</p>
<table class="table">
<caption>Execution times on an Intel Core i5 2.0-3.8 GHz CPU</caption>
<colgroup>
<col width="18%">
<col width="16%">
<col width="16%">
<col width="16%">
<col width="16%">
<col width="16%">
</colgroup>
<thead><tr class="header">
<th></th>
<th align="center">HBAM <br>iter=2000</th>
<th align="center">HBAM_NF <br>iter=2000</th>
<th align="center">HBAM_MINI <br>iter=2000</th>
<th align="center">FBAM_MINI<br>iter=2000</th>
<th align="center">FBAM_MINI <br>optimization</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>
<strong>ANES 1980</strong> <br>  (N=643, J=6)</td>
<td align="center">5m</td>
<td align="center">1m 20s</td>
<td align="center">3m 30s</td>
<td align="center">3m 45s</td>
<td align="center">3s</td>
</tr>
<tr class="even">
<td>
<strong>ANES 2012</strong> <br>  (N=4949, J=4)</td>
<td align="center">1h</td>
<td align="center">15m</td>
<td align="center">35m</td>
<td align="center">40m</td>
<td align="center">21s</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section level2">
<h2 id="plotting">Plotting<a class="anchor" aria-label="anchor" href="#plotting"></a>
</h2>
<p>The <strong>hbamr</strong> package contains several functions for
creating presentable plots of the results. The package uses
<strong>ggplot2</strong>, which means ggplot-themes can be added to the
plots.</p>
<div class="section level3">
<h3 id="stimuli-positions">Stimuli Positions<a class="anchor" aria-label="anchor" href="#stimuli-positions"></a>
</h3>
<p>The function <code><a href="../reference/plot_stimuli.html">plot_stimuli()</a></code> plots the marginal posterior
distributions of all stimuli in the data. By default, it will fill the
distributions with shades from blue to red depending on the position on
the scale. The argument <code>rev_color = TRUE</code> will reverse the
order of the colors.</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_stimuli.html">plot_stimuli</a></span><span class="op">(</span><span class="va">fit_hbam</span><span class="op">)</span></span></code></pre></div>
<p><img src="p_stim.svg" width="100%" style="display: block; margin: auto;"></p>
<p>In this example, we see that John B. Anderson – the former Republican
who ran as an independent candidate – gets a wider posterior
distribution, suggesting that voters were more uncertain about where to
place him relative to the others.</p>
</div>
<div class="section level3">
<h3 id="respondent-positions">Respondent Positions<a class="anchor" aria-label="anchor" href="#respondent-positions"></a>
</h3>
<p>The function <code><a href="../reference/plot_respondents.html">plot_respondents()</a></code> plots the distribution
of estimated respondent positions. It illustrates the uncertainty of the
estimates by calculating the population density for each of a set of
posterior draws. The default is to use 15 draws for each respondent, but
this can be altered by specifying the argument <code>n_draws</code>. The
<code><a href="../reference/plot_respondents.html">plot_respondents()</a></code> function also plots the estimated
stimulus positions by default, but this behavior can be turned off by
adding the argument <code>inc_stimuli = FALSE</code>.</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_respondents.html">plot_respondents</a></span><span class="op">(</span><span class="va">fit_hbam</span>, n_draws <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span></code></pre></div>
<p><img src="p_resp.svg" width="100%" style="display: block; margin: auto;"></p>
<p>Users who want to customize the plots further can obtain the
underlying data by using the function <code><a href="../reference/get_plot_data.html">get_plot_data()</a></code>. This
function accepts the same <code>n_draws</code>-argument as
<code><a href="../reference/plot_respondents.html">plot_respondents()</a></code>. The output is a list of three tibbles:
The first element contains the posterior mean stimulus positions, as
well as the <span class="math inline">\(x\)</span>- and <span class="math inline">\(y\)</span>-values of the posterior modes (which
can be useful for labeling the distributions). The second element
contains the posterior draws for the stimulus positions (which can be
used to calculate marginal posterior densities). The third element
contains the selected number of posterior draws for each respondent
(which form the key ingredient for the <code><a href="../reference/plot_respondents.html">plot_respondents()</a></code>
function).</p>
</div>
<div class="section level3">
<h3 id="individual-parameters-over-self-placements">Individual Parameters over Self-Placements<a class="anchor" aria-label="anchor" href="#individual-parameters-over-self-placements"></a>
</h3>
<p>The function <code><a href="../reference/plot_over_self.html">plot_over_self()</a></code> plots the distributions of
key parameter estimates over the respondents’ self-placements. The
function will accept either a single <code>stanfit</code> object
produced by <code><a href="../reference/hbam.html">hbam()</a></code>, results from <code><a href="../reference/fbam.html">fbam()</a></code>, or a
list of such objects. In addition, the function requires the list of
data that was produced by <code><a href="../reference/prep_data.html">prep_data()</a></code> before fitting the
model(s).</p>
<p>The user specifies which parameter to show via the argument
<code>par</code>. This can be either of the following:
<code>"alpha"</code>, <code>"beta"</code>, <code>"abs_beta"</code>,
<code>"lambda"</code>, or <code>"chi"</code>, where
<code>"abs_beta"</code> calls for the absolute value of beta to be used.
By default, the function uses posterior median estimates, but this can
be changed by specifying <code>estimate = "mean"</code>.</p>
<div class="section level4">
<h4 id="shifting">Shifting<a class="anchor" aria-label="anchor" href="#shifting"></a>
</h4>
<p>To compare the distributions of estimated shift parameters from the
HBAM and HBAM_MINI models, we would run:</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_over_self.html">plot_over_self</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="va">fit_hbam</span>, <span class="va">fit_hbam_mini</span><span class="op">)</span>, <span class="va">dat</span>, <span class="st">"alpha"</span><span class="op">)</span></span></code></pre></div>
<p><img src="p_alpha.svg" width="100%" style="display: block; margin: auto;"></p>
</div>
<div class="section level4">
<h4 id="stretching">Stretching<a class="anchor" aria-label="anchor" href="#stretching"></a>
</h4>
<p>For models that allow for scale flipping, the draws for <span class="math inline">\(\beta\)</span> combine the separate parameters for
each flipping-state. The absolute value of <span class="math inline">\(\beta\)</span> may therefore be better suited for
examining the extent to which each individual stretches the ideological
space. To inspect the distribution of these values across
self-placements, we would run:</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_over_self.html">plot_over_self</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="va">fit_hbam</span>, <span class="va">fit_hbam_mini</span><span class="op">)</span>, <span class="va">dat</span>, <span class="st">"abs_beta"</span><span class="op">)</span></span></code></pre></div>
<p><img src="p_abs_beta.svg" width="100%" style="display: block; margin: auto;"></p>
<p>The pattern above, where respondents with more extreme
self-placements have more extreme <span class="math inline">\(\beta\)</span> parameters, is exactly the kind of
differential item functioning that the models in this package are
intended to correct for: These respondents tend to place both stimuli
and themselves further out on the scale than others do, thus appearing
more extreme in comparison.</p>
</div>
<div class="section level4">
<h4 id="flipping">Flipping<a class="anchor" aria-label="anchor" href="#flipping"></a>
</h4>
<p>To see whether the <span class="math inline">\(\beta\)</span>
parameters are likely to be positive or negative, we can look at the
expectations of the flipping parameters, <span class="math inline">\(\lambda\)</span>. These parameters represent each
respondent’s probability of <em>not</em> flipping the scale:</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_over_self.html">plot_over_self</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="va">fit_hbam</span>, <span class="va">fit_hbam_mini</span><span class="op">)</span>, <span class="va">dat</span>, <span class="st">"lambda"</span><span class="op">)</span></span></code></pre></div>
<p><img src="p_lambda.svg" width="100%" style="display: block; margin: auto;"></p>
<p>In this example, flipping is uncommon, but respondents who place
themselves in the middle have a somewhat higher flipping-probability.
This may suggest that some of these respondents are less informed about
politics and provide less accurate answers.</p>
</div>
<div class="section level4">
<h4 id="respondent-positions-1">Respondent Positions<a class="anchor" aria-label="anchor" href="#respondent-positions-1"></a>
</h4>
<p>It may also be useful to inspect the distribution of the scaled
respondent positions over the self-placements. This illustrates the
extent to which the model has transformed the original data. In this
example, the impact of the models is generally modest, although a few
respondents have been detected as having flipped the scale, and thus
have had their self-placement flipped back.</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_over_self.html">plot_over_self</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="va">fit_hbam</span>, <span class="va">fit_hbam_mini</span><span class="op">)</span>, <span class="va">dat</span>, <span class="st">"chi"</span><span class="op">)</span></span></code></pre></div>
<p><img src="p_chi.svg" width="100%" style="display: block; margin: auto;"></p>
</div>
<div class="section level4">
<h4 id="additional-parameters">Additional Parameters<a class="anchor" aria-label="anchor" href="#additional-parameters"></a>
</h4>
<p>Other individual-level parameters like <code>"eta"</code> can also be
plotted if these have been passed to <code><a href="../reference/hbam.html">hbam()</a></code> via the
argument <code>extra_pars</code> when fitting the model. Parameters like
<span class="math inline">\(\eta\)</span> are not stored in the
<code><a href="../reference/hbam.html">hbam()</a></code> results by default, as this would increase the
post-processing time as well as the size of the model fits. (Note also
that homoskedastic models have no <code>"eta"</code> parameters and
“NF”-type models have no <code>"lambda"</code> or <code>"kappa"</code>
parameters.)</p>
<p>The estimated <span class="math inline">\(\eta\)</span> parameters
yield information about the accuracy of respondents’ answers. When the
argument <code>par = "eta"</code> is specified, the plotting function
will display <span class="math inline">\(\sqrt{\eta_i} / J\)</span>,
which equals the average error for each individual (the mean of <span class="math inline">\(\sigma_{ij}\)</span> for each <span class="math inline">\(i\)</span> across <span class="math inline">\(j\)</span>). The point estimates will still be
calculated using the posterior median, unless the argument
<code>estimate = "mean"</code> is added.</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_hbam</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/hbam.html">hbam</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">dat</span>, extra_pars <span class="op">=</span> <span class="st">"eta"</span><span class="op">)</span></span>
<span><span class="fu"><a href="../reference/plot_over_self.html">plot_over_self</a></span><span class="op">(</span><span class="va">fit_hbam</span>, <span class="va">dat</span>, <span class="st">"eta"</span><span class="op">)</span></span></code></pre></div>
<p><img src="p_eta.svg" width="50%" style="display: block; margin: auto;"></p>
</div>
</div>
</div>
<div class="section level2">
<h2 id="posterior-summaries">Posterior Summaries<a class="anchor" aria-label="anchor" href="#posterior-summaries"></a>
</h2>
<p>The package also contains a wrapper for <code>rstan::summary()</code>
called <code><a href="../reference/get_est.html">get_est()</a></code>. This function takes the arguments
<code>object</code> – a <code>stanfit</code> object produced by
<code><a href="../reference/hbam.html">hbam()</a></code> or a list produced by <code><a href="../reference/fbam.html">fbam()</a></code> – and
<code>par</code> – the name of the parameter(s) to be summarized. The
function returns a tibble, which by default contains the posterior mean,
the 95% credible interval, the posterior median, the estimated number of
effective draws, and the split R-hat. One can obtain other posterior
quantiles by using the argument <code>probs</code>. To get a 50%
credible interval (and no median), one would add the argument
<code>probs = c(0.25, 0.75)</code>. To include the Monte Carlo standard
error and the posterior standard deviation, use the argument
<code>simplify = FALSE</code>. (When applied to outputs from
<code><a href="../reference/fbam.html">fbam()</a></code>, <code><a href="../reference/get_est.html">get_est()</a></code> only returns point
estimates.)</p>
<p>The posterior draws for the stimulus positions can be summarized as
follows:</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/get_est.html">get_est</a></span><span class="op">(</span><span class="va">fit_hbam</span>, <span class="st">"theta"</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## <span style="color: #949494;"># A tibble: 6 × 6</span></span></span>
<span><span class="co">##     mean `2.5%`  `50%` `97.5%` n_eff  Rhat</span></span>
<span><span class="co">##    <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>  <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>  <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>   <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span></span></span>
<span><span class="co">## <span style="color: #BCBCBC;">1</span> -<span style="color: #BB0000;">1.02</span>  -<span style="color: #BB0000;">1.10</span>  -<span style="color: #BB0000;">1.02</span>   -<span style="color: #BB0000;">0.941</span> <span style="text-decoration: underline;">2</span>160. 1.00 </span></span>
<span><span class="co">## <span style="color: #BCBCBC;">2</span>  1.62   1.55   1.62    1.68  <span style="text-decoration: underline;">2</span>013. 1.00 </span></span>
<span><span class="co">## <span style="color: #BCBCBC;">3</span> -<span style="color: #BB0000;">1.68</span>  -<span style="color: #BB0000;">1.76</span>  -<span style="color: #BB0000;">1.68</span>   -<span style="color: #BB0000;">1.60</span>  <span style="text-decoration: underline;">2</span>473. 1.00 </span></span>
<span><span class="co">## <span style="color: #BCBCBC;">4</span> -<span style="color: #BB0000;">0.453</span> -<span style="color: #BB0000;">0.574</span> -<span style="color: #BB0000;">0.453</span>  -<span style="color: #BB0000;">0.333</span> <span style="text-decoration: underline;">3</span>159. 1.00 </span></span>
<span><span class="co">## <span style="color: #BCBCBC;">5</span>  1.42   1.36   1.42    1.48  <span style="text-decoration: underline;">1</span>912. 1.00 </span></span>
<span><span class="co">## <span style="color: #BCBCBC;">6</span> -<span style="color: #BB0000;">1.19</span>  -<span style="color: #BB0000;">1.25</span>  -<span style="color: #BB0000;">1.19</span>   -<span style="color: #BB0000;">1.13</span>  <span style="text-decoration: underline;">2</span>404. 0.999</span></span></code></pre>
<p>The equivalent call for the respondent positions is:</p>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/get_est.html">get_est</a></span><span class="op">(</span><span class="va">fit_hbam</span>, <span class="st">"chi"</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## <span style="color: #949494;"># A tibble: 643 × 6</span></span></span>
<span><span class="co">##       mean `2.5%`    `50%` `97.5%` n_eff  Rhat</span></span>
<span><span class="co">##      <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>  <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>    <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>   <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span></span></span>
<span><span class="co">## <span style="color: #BCBCBC;"> 1</span>  0.965  -<span style="color: #BB0000;">1.96</span>   1.27      2.62  <span style="text-decoration: underline;">2</span>862.  1.00</span></span>
<span><span class="co">## <span style="color: #BCBCBC;"> 2</span>  1.21   -<span style="color: #BB0000;">0.613</span>  1.26      2.57  <span style="text-decoration: underline;">3</span>421.  1.00</span></span>
<span><span class="co">## <span style="color: #BCBCBC;"> 3</span>  1.39   -<span style="color: #BB0000;">0.121</span>  1.44      2.35  <span style="text-decoration: underline;">3</span>212.  1.00</span></span>
<span><span class="co">## <span style="color: #BCBCBC;"> 4</span>  0.012<span style="text-decoration: underline;">8</span> -<span style="color: #BB0000;">1.80</span>   0.004<span style="text-decoration: underline;">69</span>   1.76  <span style="text-decoration: underline;">3</span>745.  1.00</span></span>
<span><span class="co">## <span style="color: #BCBCBC;"> 5</span> -<span style="color: #BB0000;">0.197</span>  -<span style="color: #BB0000;">2.04</span>  -<span style="color: #BB0000;">0.253</span>     1.89  <span style="text-decoration: underline;">4</span>089.  1.00</span></span>
<span><span class="co">## <span style="color: #BCBCBC;"> 6</span>  1.45   -<span style="color: #BB0000;">1.78</span>   1.68      2.94  <span style="text-decoration: underline;">2</span>336.  1.00</span></span>
<span><span class="co">## <span style="color: #BCBCBC;"> 7</span> -<span style="color: #BB0000;">0.157</span>  -<span style="color: #BB0000;">1.15</span>  -<span style="color: #BB0000;">0.159</span>     0.857 <span style="text-decoration: underline;">2</span>975.  1.00</span></span>
<span><span class="co">## <span style="color: #BCBCBC;"> 8</span>  0.943  -<span style="color: #BB0000;">0.738</span>  0.991     2.01  <span style="text-decoration: underline;">2</span>924.  1.00</span></span>
<span><span class="co">## <span style="color: #BCBCBC;"> 9</span>  0.587  -<span style="color: #BB0000;">0.857</span>  0.623     1.73  <span style="text-decoration: underline;">3</span>691.  1.00</span></span>
<span><span class="co">## <span style="color: #BCBCBC;">10</span>  0.125  -<span style="color: #BB0000;">1.02</span>   0.136     1.14  <span style="text-decoration: underline;">3</span>654.  1.00</span></span>
<span><span class="co">## <span style="color: #949494;"># ℹ 633 more rows</span></span></span></code></pre>
</div>
<div class="section level2">
<h2 id="cross-validation">Cross-Validation<a class="anchor" aria-label="anchor" href="#cross-validation"></a>
</h2>
<p>A useful way to compare alternative models is to estimate their
out-of-sample prediction accuracy. More specifically, we can estimate
their expected log pointwise predictive density for a new data set
(ELPD).</p>
<p>The <strong>rstan</strong> and <strong>loo</strong> packages contain
functions for estimating ELPDs by performing approximate leave-one-out
(LOO) cross-validation using Pareto smoothed importance sampling (PSIS).
These functions can be used on model fits from <code><a href="../reference/hbam.html">hbam()</a></code> if
the argument <code>extra_pars = "log_lik"</code> is specified when
fitting the model:</p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_hbam</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/hbam.html">hbam</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">dat</span>, extra_pars <span class="op">=</span> <span class="st">"log_lik"</span><span class="op">)</span></span>
<span><span class="va">loo_hbam</span> <span class="op">&lt;-</span> <span class="fu">loo</span><span class="fu">::</span><span class="fu"><a href="https://mc-stan.org/loo/reference/loo.html" class="external-link">loo</a></span><span class="op">(</span><span class="va">fit_hbam</span><span class="op">)</span></span></code></pre></div>
<p>However, PSIS-LOO only works when all Pareto <em>k</em> values are
sufficiently low, or when the number of high values is so low that
moment matching can be used on the problematic cases. This is not always
the case for the models in this package.</p>
<p>The <strong>hbamr</strong> package therefore allows users to perform
<em>K</em>-fold cross-validation. The function <code><a href="../reference/hbam_cv.html">hbam_cv()</a></code> is
similar to <code><a href="../reference/hbam.html">hbam()</a></code> and takes the same arguments, but will
perform a <em>K</em>-fold cross-validation for the chosen model. In
contrast to <code><a href="../reference/hbam.html">hbam()</a></code>, the default for <code><a href="../reference/hbam_cv.html">hbam_cv()</a></code>
is to not allow respondents to have any missing values
(<code>allow_miss = 0</code>). The reason is that the cross-validation
essentially creates missing values by excluding some data from each
run.</p>
<p>A key choice when performing cross-validation is to set <em>K</em>
(the number of folds to use), and the default in this package is 10. To
preserve memory, the function extracts the summaries of the
log-likelihoods for the held-out data and drops the stanfit objects once
this is done. The memory requirements of the function is therefore
similar to running a single analysis with one chain per core. The
function that splits the data into <em>K</em> folds uses a default seed
to produce the same folds each time, unless a different seed is
specified.</p>
<p>The <code><a href="../reference/hbam_cv.html">hbam_cv()</a></code> function is written to allow parallel
computation via the <code>future</code> package to minimize execution
time. The <code>future</code> package offers several computational
strategies, of which “multisession” works on all operating systems. It
most settings, it is advisable to use all physical CPU cores when
performing cross-validation. To set up parallel computation using 4
cores via the <code>future</code> package, we could run:</p>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://future.futureverse.org" class="external-link">future</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://future.futureverse.org/reference/plan.html" class="external-link">plan</a></span><span class="op">(</span><span class="va">multisession</span>, workers <span class="op">=</span> <span class="fl">4</span><span class="op">)</span></span></code></pre></div>
<p>To perform 10-fold cross-validation for a selection of models, we
could run:</p>
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">kfold_bam</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/hbam_cv.html">hbam_cv</a></span><span class="op">(</span><span class="va">self</span>, <span class="va">stimuli</span>, model <span class="op">=</span> <span class="st">"BAM"</span><span class="op">)</span></span>
<span><span class="va">kfold_hbam</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/hbam_cv.html">hbam_cv</a></span><span class="op">(</span><span class="va">self</span>, <span class="va">stimuli</span>, model <span class="op">=</span> <span class="st">"HBAM"</span><span class="op">)</span></span>
<span><span class="va">kfold_hbam_nf</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/hbam_cv.html">hbam_cv</a></span><span class="op">(</span><span class="va">self</span>, <span class="va">stimuli</span>, model <span class="op">=</span> <span class="st">"HBAM_NF"</span><span class="op">)</span></span>
<span><span class="va">kfold_hbam_multi</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/hbam_cv.html">hbam_cv</a></span><span class="op">(</span><span class="va">self</span>, <span class="va">stimuli</span>, group_id <span class="op">=</span> <span class="va">self</span>, </span>
<span>                            model <span class="op">=</span> <span class="st">"HBAM_MULTI"</span><span class="op">)</span></span></code></pre></div>
<p>The <code><a href="../reference/hbam_cv.html">hbam_cv()</a></code> function returns an object of classes
<code>kfold</code> and <code>loo</code>, which can be further processed
using the <code>loo</code> package. To compare the estimated ELPDs, we
could run:</p>
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="fu">loo</span><span class="fu">::</span><span class="fu"><a href="https://mc-stan.org/loo/reference/loo_compare.html" class="external-link">loo_compare</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>BAM <span class="op">=</span> <span class="va">kfold_bam</span>, </span>
<span>                            HBAM <span class="op">=</span> <span class="va">kfold_hbam</span>, </span>
<span>                            HBAM_NF <span class="op">=</span> <span class="va">kfold_hbam_nf</span>, </span>
<span>                            HBAM_MULTI <span class="op">=</span> <span class="va">kfold_hbam_multi</span><span class="op">)</span><span class="op">)</span>, simplify <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##            elpd_diff se_diff elpd_kfold se_elpd_kfold</span></span>
<span><span class="co">## HBAM_MULTI     0.0       0.0 -5503.3       49.2      </span></span>
<span><span class="co">## HBAM          -8.6       8.8 -5511.9       49.3      </span></span>
<span><span class="co">## HBAM_NF     -255.5      27.7 -5758.7       51.3      </span></span>
<span><span class="co">## BAM         -331.5      38.4 -5834.8       58.7</span></span></code></pre>
<p>We see that the unpooled BAM model is worse at predicting
out-of-sample data than the other models, suggesting it overfits the
data. The HBAM_NF model – which does not allow for scale flipping – also
performs worse, suggesting it is too restrictive and underfits. The HBAM
and HBAM_MULTI models outperform the other two models in this case. The
HBAM_MULTI model – with self-placements as <code>group_id</code> – may
have a slight edge, but the default HBAM model performs about equally
well.</p>
<p>We could also perform cross-validation for a couple of models that do
not account for heteroskedastic errors:</p>
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">kfold_hbam_mini</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/hbam_cv.html">hbam_cv</a></span><span class="op">(</span><span class="va">self</span>, <span class="va">stimuli</span>, model <span class="op">=</span> <span class="st">"HBAM_MINI"</span><span class="op">)</span></span>
<span><span class="va">kfold_fbam_mini</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/hbam_cv.html">hbam_cv</a></span><span class="op">(</span><span class="va">self</span>, <span class="va">stimuli</span>, model <span class="op">=</span> <span class="st">"FBAM_MINI"</span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb28"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="fu">loo</span><span class="fu">::</span><span class="fu"><a href="https://mc-stan.org/loo/reference/loo_compare.html" class="external-link">loo_compare</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>HBAM_MINI <span class="op">=</span> <span class="va">kfold_hbam_mini</span>, </span>
<span>                            FBAM_MINI <span class="op">=</span> <span class="va">kfold_fbam_mini</span><span class="op">)</span><span class="op">)</span>, simplify <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##           elpd_diff se_diff elpd_kfold se_elpd_kfold</span></span>
<span><span class="co">## HBAM_MINI     0.0       0.0 -5882.0       48.6      </span></span>
<span><span class="co">## FBAM_MINI  -158.7      22.9 -6040.7       46.0</span></span></code></pre>
<p>The ELPD for the FBAM_MINI model is lower than that of the HBAM_MINI
model, which suggests that the default priors of the FBAM model are too
wide to yield optimal results for these data. While the ELPD for the
HBAM_MINI model is higher than that of the FBAM model, it is still
notably lower than that of its heteroskedastic counterpart (HBAM). This
suggest there is a considerable degree of heteroskedasticity in the data
– which is not surprising.</p>
<p>Modeling the heteroskedasticity increases prediction accuracy, but it
should be noted that this does not necessarily translate into much more
accurate estimates of key model outputs. As shown in section on
plotting, the results for the HBAM and HBAM_MINI models are very
similar. In fact, their estimated respondent positions correlate at .97
and .99, depending on whether we use the posterior means or medians.
Their estimated stimulus positions also correlate at .99, but this masks
the fact that the HBAM_MINI model places the less well known candidate
John B. Anderson further to the left than the HBAM model does. There are
some subtle differences that users should be aware of, even if these
models tend to produce very similar results.</p>
</div>
<div class="section level2">
<h2 id="diagnostics">Diagnostics<a class="anchor" aria-label="anchor" href="#diagnostics"></a>
</h2>
<p>The <code><a href="https://mc-stan.org/rstan/reference/stanmodel-method-sampling.html" class="external-link">rstan::sampling()</a></code> function that <code><a href="../reference/hbam.html">hbam()</a></code>
uses automatically performs a number of key diagnostic checks after
sampling and issues warnings when a potential issue is detected. The
authors of <strong>rstan</strong> emphasize diagnostics and careful
model development, and users of <strong>rstan</strong> will more
frequently encounter warnings than users of <strong>rjags</strong>. One
warning users of this package may encounter is that the Bulk or Tail
Effective Sample Size (ESS) is too low (see <a href="https://mc-stan.org/misc/warnings.html" class="external-link uri">https://mc-stan.org/misc/warnings.html</a>). The most
straightforward solution to this issue is to increase the number of
posterior draws, using the <code>iter</code> argument. However, this
increases the computational load, and users should consider carefully
what level of accuracy they need.</p>
<p>Because the <code><a href="../reference/hbam.html">hbam()</a></code> function returns a
<code>stanfit</code> object, the model fit can be examined using the
full range of diagnostic tools from the <strong>rstan</strong> package.
Users should consult the <strong>rstan</strong> documentation for
details on the various diagnostic tests and plots that are available.
One example of the available tools is <code>traceplot()</code>:</p>
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">rstan</span><span class="fu">::</span><span class="fu"><a href="https://mc-stan.org/rstan/reference/stanfit-method-traceplot.html" class="external-link">traceplot</a></span><span class="op">(</span><span class="va">fit_hbam</span>, pars <span class="op">=</span> <span class="st">"theta"</span><span class="op">)</span></span></code></pre></div>
<p><img src="p_trace_theta.svg" width="100%" style="display: block; margin: auto;"></p>
<div class="section level3">
<h3 id="limits-to-exact-replication">Limits to Exact Replication<a class="anchor" aria-label="anchor" href="#limits-to-exact-replication"></a>
</h3>
<p>The functions in this package accept a seed argument for all
operations that involve a random number generator. Supplying a seed is
sufficient to get the exact same results in repeated runs on the same
system, but it does not ensure exact replication across systems or
software versions. The <a href="https://mc-stan.org/docs/reference-manual/reproducibility.html" class="external-link">Stan
Reference Manual</a> explains why:</p>
<blockquote>
<p>Floating point operations on modern computers are notoriously
difficult to replicate because the fundamental arithmetic operations,
right down to the IEEE 754 encoding level, are not fully specified. The
primary problem is that the precision of operations varies across
different hardware platforms and software implementations.</p>
<p>Stan is designed to allow full reproducibility. However, this is only
possible up to the external constraints imposed by floating point
arithmetic.</p>
</blockquote>
<p>In short, running the functions in this package on different systems
will likely yield slightly different results. It should be noted,
however, that the differences across systems will be minimal and
substantively negligible as long as the user obtains a sufficient number
of posterior draws.</p>
</div>
</div>
<div class="section level2 unnumbered">
<h2 class="unnumbered" id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-aldrich:1977" class="csl-entry">
Aldrich, John H, and Richard D McKelvey. 1977. <span>“<span class="nocase">A Method of Scaling with Applications to the 1968 and
1972 Presidential Elections</span>.”</span> <em>American Political
Science Review</em> 71(1): 111–130.
</div>
<div id="ref-boelstad:2020" class="csl-entry">
Bølstad, Jørgen. 2020. <span>“<span class="nocase">Capturing
Rationalization Bias and Differential Item Functioning: A Unified
<span>B</span>ayesian Scaling Approach</span>.”</span> <em>Political
Analysis</em> 28(3): 340–355.
</div>
<div id="ref-boelstad:2023" class="csl-entry">
Bølstad, Jørgen. 2024. <span>“<span>Hierarchical Bayesian
Aldrich-McKelvey Scaling</span>.”</span> <em>Political Analysis</em>
32(1): 50–64. <a href="https://doi.org/10.1017/pan.2023.18" class="external-link">https://doi.org/10.1017/pan.2023.18</a>.
</div>
<div id="ref-hare:2015" class="csl-entry">
Hare, Christopher et al. 2015. <span>“<span class="nocase">Using
<span>B</span>ayesian <span>A</span>ldrich-<span>M</span>cKelvey Scaling
to Study Citizens’ Ideological Preferences and
Perceptions</span>.”</span> <em>American Journal of Political
Science</em> 59(3): 759–774.
</div>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Jørgen Bølstad.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
