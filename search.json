[{"path":"https://jbolstad.github.io/hbamr/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"https://jbolstad.github.io/hbamr/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"https://jbolstad.github.io/hbamr/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"https://jbolstad.github.io/hbamr/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"https://jbolstad.github.io/hbamr/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"https://jbolstad.github.io/hbamr/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"https://jbolstad.github.io/hbamr/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"https://jbolstad.github.io/hbamr/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"https://jbolstad.github.io/hbamr/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"https://jbolstad.github.io/hbamr/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"https://jbolstad.github.io/hbamr/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"https://jbolstad.github.io/hbamr/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"https://jbolstad.github.io/hbamr/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"https://jbolstad.github.io/hbamr/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"https://jbolstad.github.io/hbamr/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"https://jbolstad.github.io/hbamr/LICENSE.html","id":"id_13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"https://jbolstad.github.io/hbamr/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"https://jbolstad.github.io/hbamr/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"https://jbolstad.github.io/hbamr/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"https://jbolstad.github.io/hbamr/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"https://jbolstad.github.io/hbamr/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. program terminal interaction, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, program’s commands might different; GUI interface, use “box”. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. information , apply follow GNU GPL, see <http://www.gnu.org/licenses/>. GNU General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License. first, please read <http://www.gnu.org/philosophy/--lgpl.html>.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) <year>  <name of author>  This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program.  If not, see <http://www.gnu.org/licenses/>. <program>  Copyright (C) <year>  <name of author> This program comes with ABSOLUTELY NO WARRANTY; for details type 'show w'. This is free software, and you are welcome to redistribute it under certain conditions; type 'show c' for details."},{"path":"https://jbolstad.github.io/hbamr/articles/hbamr.html","id":"example-data","dir":"Articles","previous_headings":"","what":"Example Data","title":"Hierarchical Bayesian Aldrich-McKelvey Scaling in R via Stan","text":"illustration, use data 1980 American National Election Study (ANES). data set serves illustrate original model basicspace package. data set included hbamr package can loaded running data(LC1980). data set contains respondents’ placements six stimuli 7-point Liberal-Conservative scales. stimuli question : Democratic Republican parties, Democratic presidential candidate Jimmy Carter, Republican candidate Ronald Reagan, independent candidate (former Republican) John B. Anderson, Ted Kennedy (challenged incumbent Carter, failed win Democratic nomination). load data re-code missing values follows:","code":"library(\"hbamr\") data(LC1980) LC1980[LC1980 == 0 | LC1980 == 8 | LC1980 == 9] <- NA  self <- LC1980[, 1] stimuli <- LC1980[, -1] head(stimuli) ##    Carter Reagan Kennedy Anderson Republicans Democrats ## 1       2      6       1        7           5         5 ## 8       4      6       4        7           6         4 ## 9       3      6       3        3           6         2 ## 10      6      4       3        3           5         4 ## 11      7      2       5        5           7         5 ## 13      6      6       2        5           7         4"},{"path":"https://jbolstad.github.io/hbamr/articles/hbamr.html","id":"preparing-the-data","dir":"Articles","previous_headings":"","what":"Preparing the Data","title":"Hierarchical Bayesian Aldrich-McKelvey Scaling in R via Stan","text":"function prep_data() serves prepare data. function can run ahead fitting models, can run implicitly part single function call fit models (shown ). function takes vector \\(N\\) ideological self-placements \\(N \\times J\\) matrix stimulus placements. applies set inclusion criteria, performs necessary data transformation, returns list data suited sampling rstan. stimuli data stored vector long-form sparse matrix. stimuli data include column-names, preserved later use. missing data must set NA use. prep_data() function allows user decide many missing values permitted per respondent specifying argument allow_miss. (default allow_miss = 2. Alternatively, argument req_valid specifies many valid observations require per respondent. default req_valid = J - allow_miss, , specified, req_valid takes precedence.) Similarly, user may specify may unique positions ideological scale respondent required used placing stimuli order included analysis. default req_unique = 2, means respondents place stimuli exactly place included. data provided prep_data() can centered, : function detect un-centered data attempt center automatically, assuming highest lowest observed values data mark extremes scale. use prep_data() function example data using default settings, run: Users want keep covariates subsequent analysis, may find useful run prep_data() separately call fit models. list returned function includes logical vector keep, identifies rows original data kept. data set x containing covariates, used prep_data() produce list dat, use x[dat$keep, ] get subset x corresponding data used analysis. (order individuals/rows data remains unchanged functions package.)","code":"dat <- prep_data(self, stimuli)"},{"path":"https://jbolstad.github.io/hbamr/articles/hbamr.html","id":"models","dir":"Articles","previous_headings":"","what":"Models","title":"Hierarchical Bayesian Aldrich-McKelvey Scaling in R via Stan","text":"package provides several alternative models can selected using names . Users unsure model use advised use default HBAM model. speed sampling diagnostics issue, HBAM_MINI may provide useful alternative. HBAM default model, allows scale flipping employs hierarchical priors shift stretch parameters. also models heteroskedastic errors vary individual stimuli. Compared model Bølstad (2024), version slightly revised provide faster sampling. key difference original model respondent positions treated parameters, rather calculated function self-placements, individual-level parameters, simulated errors. makes model considerably faster, yielding similar results. model simulates errors self-placements magnitude respondent question places stimulus smallest errors. models package use approach. HBAM_MULTI version models differences groups defined user. requires integer vector identifying groups supplied argument group_id. model gives group separate hyperparameters locations prior distributions shift stretch parameters. Rather shrinking estimates toward mode whole dataset, model shrinks estimates toward mode group. vectors hyperparameters called mu_alpha mu_beta constructed means 0. scales priors hyperparameters can set user via arguments sigma_mu_alpha sigma_mu_beta. default values B / 5 .3, respectively. (, B measures length survey scale number possible placements one side center.) One potential use model supply self-placements (appropriately transformed) group_id, thus give self-placement group prior distribution shift stretch parameters. HBAM_NF (formerly HBAM_0) version HBAM model allow scale flipping. may useful truly zero cases scale flipping data. scenarios can created artificially, may also arise real data. example, expert surveys appear unlikely contain many instances scale flipping. data contain zero cases flipping, models allow flipping contain superfluous parameters lead inefficient sampling. Models allow flipping sample faster typically yield slightly accurate estimates. models therefore preferable flipping present. HBAM_MULTI_NF version HBAM_MULTI model allow scale flipping. HBAM_MINI version HBAM model assumes prediction errors stimuli placements homoskedastic. model tends sample faster faster standard HBAM model yielding similar point estimates. large datasets, model may provide reasonable compromise model complexity estimation speed. FBAM_MINI version HBAM_MINI model fixed hyperparameters allow fitting via optimization rather MCMC – can useful large data sets. model allows user specify scales priors shift (logged) stretch parameters via arguments sigma_alpha sigma_beta. default values B / 4 .35, respectively. defaults intended realistic weakly informative. Users want control degree shrinkage individual-level parameters may find useful fit model – FBAM models – via either MCMC optimization. FBAM_MULTI version FBAM_MINI model shares group-modeling features HBAM_MULTI model. allows user set scales priors shift stretch parameters via arguments sigma_alpha sigma_beta, set scales priors mu_alpha mu_beta via arguments sigma_mu_alpha sigma_mu_beta. FBAM_MULTI_NF version FBAM_MULTI model allow scale flipping. HBAM_R_MINI version HBAM_MINI model incorporates rationalization component ISR model Bølstad (2020). model requires additional data supplied argument pref: N × J matrix stimuli ratings respondents. rationalization part model simplified relative original ISR model: direction respondents move disfavored stimuli estimated common expectation possible self-placement scale. BAM unpooled model wide uniform priors shift stretch parameters. similar JAGS version introduced Hare et al. (2015). model mainly provided offer baseline model comparisons. simple fast, model tends overfit data produce invalid posterior distributions respondent positions (Bølstad 2024). HBAM_2 deprecated replaced general HBAM_MULTI model. models can also used situations self-placements available goal estimate stimulus positions. can achieved supplying vector zeros (random data) instead real self-placements: self = rep(0, nrow(stimuli)). see Stan code models, use show_code() function:","code":"show_code(\"HBAM_MULTI\")"},{"path":"https://jbolstad.github.io/hbamr/articles/hbamr.html","id":"summary-of-model-features","dir":"Articles","previous_headings":"Models","what":"Summary of Model Features","title":"Hierarchical Bayesian Aldrich-McKelvey Scaling in R via Stan","text":"Recommended models fitting via MCMC Non-hierarchical, specialized, historical models (“*” marks optional features)","code":""},{"path":"https://jbolstad.github.io/hbamr/articles/hbamr.html","id":"fitting","dir":"Articles","previous_headings":"","what":"Fitting","title":"Hierarchical Bayesian Aldrich-McKelvey Scaling in R via Stan","text":"hbam() function can used fit models package returns stanfit object. default model HBAM, models can specified via argument model. model, hbam() selects suitable function produce initial values sampling algorithm. Unless user supplies pre-prepared data via data-argument, hbam() implicitly run prep_data(). therefore takes arguments prep_data() function (.e. self, stimuli, allow_miss, req_valid, req_unique). fit HBAM model using default settings, run: fit HBAM_MINI model requiring complete data respondents, run: wanted run prep_data() function separately fitting model, supply output prep_data() argument data: fit HBAM_MULTI FBAM_MULTI model, need supply vector identifying groups interest. One option give self-placement group prior distributions shift stretch parameters. (Note supplying raw self-placements group_id works case self-placements stored positive integers 1 7 – otherwise re-coded.) decided fit FBAM_MULTI model, also specify scales priors key parameters: hbam() uses rstan::sampling(), additional arguments hbam() passed sampling function. default, hbam() run 4 chains detect number available CPU cores. possible, hbam() use many cores chains. sampling defaults : warmup = 1000 iter = 2000. settings can overridden hbam() call.","code":"fit_hbam <- hbam(self, stimuli) fit_hbam_mini <- hbam(self, stimuli, model = \"HBAM_MINI\", allow_miss = 0) dat <- prep_data(self, stimuli, allow_miss = 0)  fit_hbam <- hbam(data = dat) fit_fbam_multi <- hbam(self, stimuli, model = \"FBAM_MULTI\", group_id = self,                         sigma_alpha = .8, sigma_mu_alpha = .5,                         sigma_beta = .4, sigma_mu_beta = .25)"},{"path":"https://jbolstad.github.io/hbamr/articles/hbamr.html","id":"fitting-via-optimization","dir":"Articles","previous_headings":"Fitting","what":"Fitting via Optimization","title":"Hierarchical Bayesian Aldrich-McKelvey Scaling in R via Stan","text":"large data sets, optimization can useful much faster alternative MCMC. However, optimization feature provided package provides maximum posteriori (MAP) point estimates. fbam() function fits FBAM models using rstan::optimizing(). fbam() function works just like hbam() function, except arguments rstan::sampling() apply. fit FBAM_MINI model using default settings, run:","code":"fit_fbam <- fbam(self, stimuli)"},{"path":"https://jbolstad.github.io/hbamr/articles/hbamr.html","id":"execution-times","dir":"Articles","previous_headings":"Fitting","what":"Execution Times","title":"Hierarchical Bayesian Aldrich-McKelvey Scaling in R via Stan","text":"Models kind included hbamr package face inevitable trade-nuance (.e. model complexity) execution times. small data sets (like ANES 1980), models provide reasonable running times, large data sets (like ANES 2012), complex models tend get slow. cases, HBAM_MINI model may useful alternative. large data sets, fitting FBAM_MINI model via optimization may best alternative. Execution times Intel Core i5 2.0-3.8 GHz CPU","code":""},{"path":"https://jbolstad.github.io/hbamr/articles/hbamr.html","id":"plotting","dir":"Articles","previous_headings":"","what":"Plotting","title":"Hierarchical Bayesian Aldrich-McKelvey Scaling in R via Stan","text":"hbamr package contains several functions creating presentable plots results. package uses ggplot2, means ggplot-themes can added plots.","code":""},{"path":"https://jbolstad.github.io/hbamr/articles/hbamr.html","id":"stimuli-positions","dir":"Articles","previous_headings":"Plotting","what":"Stimuli Positions","title":"Hierarchical Bayesian Aldrich-McKelvey Scaling in R via Stan","text":"function plot_stimuli() plots marginal posterior distributions stimuli data. default, fill distributions shades blue red depending position scale. argument rev_color = TRUE reverse order colors.  example, see John B. Anderson – former Republican ran independent candidate – gets wider posterior distribution, suggesting voters uncertain place relative others.","code":"plot_stimuli(fit_hbam)"},{"path":"https://jbolstad.github.io/hbamr/articles/hbamr.html","id":"respondent-positions","dir":"Articles","previous_headings":"Plotting","what":"Respondent Positions","title":"Hierarchical Bayesian Aldrich-McKelvey Scaling in R via Stan","text":"function plot_respondents() plots distribution estimated respondent positions. illustrates uncertainty estimates calculating population density set posterior draws. default use 15 draws respondent, can altered specifying argument n_draws. plot_respondents() function also plots estimated stimulus positions default, behavior can turned adding argument inc_stimuli = FALSE.  Users want customize plots can obtain underlying data using function get_plot_data(). function accepts n_draws-argument plot_respondents(). output list three tibbles: first element contains posterior mean stimulus positions, well \\(x\\)- \\(y\\)-values posterior modes (can useful labeling distributions). second element contains posterior draws stimulus positions (can used calculate marginal posterior densities). third element contains selected number posterior draws respondent (form key ingredient plot_respondents() function).","code":"plot_respondents(fit_hbam, n_draws = 10)"},{"path":"https://jbolstad.github.io/hbamr/articles/hbamr.html","id":"individual-parameters-over-self-placements","dir":"Articles","previous_headings":"Plotting","what":"Individual Parameters over Self-Placements","title":"Hierarchical Bayesian Aldrich-McKelvey Scaling in R via Stan","text":"function plot_over_self() plots distributions key parameter estimates respondents’ self-placements. function accept either single stanfit object produced hbam(), results fbam(), list objects. addition, function requires list data produced prep_data() fitting model(s). user specifies parameter show via argument par. can either following: \"alpha\", \"beta\", \"abs_beta\", \"lambda\", \"chi\", \"abs_beta\" calls absolute value beta used. default, function uses posterior median estimates, can changed specifying estimate = \"mean\".","code":""},{"path":"https://jbolstad.github.io/hbamr/articles/hbamr.html","id":"shifting","dir":"Articles","previous_headings":"Plotting > Individual Parameters over Self-Placements","what":"Shifting","title":"Hierarchical Bayesian Aldrich-McKelvey Scaling in R via Stan","text":"compare distributions estimated shift parameters HBAM HBAM_MINI models, run:","code":"plot_over_self(list(fit_hbam, fit_hbam_mini), dat, \"alpha\")"},{"path":"https://jbolstad.github.io/hbamr/articles/hbamr.html","id":"stretching","dir":"Articles","previous_headings":"Plotting > Individual Parameters over Self-Placements","what":"Stretching","title":"Hierarchical Bayesian Aldrich-McKelvey Scaling in R via Stan","text":"models allow scale flipping, draws \\(\\beta\\) combine separate parameters flipping-state. absolute value \\(\\beta\\) may therefore better suited examining extent individual stretches ideological space. inspect distribution values across self-placements, run:  pattern , respondents extreme self-placements extreme \\(\\beta\\) parameters, exactly kind differential item functioning models package intended correct : respondents tend place stimuli scale others , thus appearing extreme comparison.","code":"plot_over_self(list(fit_hbam, fit_hbam_mini), dat, \"abs_beta\")"},{"path":"https://jbolstad.github.io/hbamr/articles/hbamr.html","id":"flipping","dir":"Articles","previous_headings":"Plotting > Individual Parameters over Self-Placements","what":"Flipping","title":"Hierarchical Bayesian Aldrich-McKelvey Scaling in R via Stan","text":"see whether \\(\\beta\\) parameters likely positive negative, can look expectations flipping parameters, \\(\\lambda\\). parameters represent respondent’s probability flipping scale:  example, flipping uncommon, respondents place middle somewhat higher flipping-probability. may suggest respondents less informed politics provide less accurate answers.","code":"plot_over_self(list(fit_hbam, fit_hbam_mini), dat, \"lambda\")"},{"path":"https://jbolstad.github.io/hbamr/articles/hbamr.html","id":"respondent-positions-1","dir":"Articles","previous_headings":"Plotting > Individual Parameters over Self-Placements","what":"Respondent Positions","title":"Hierarchical Bayesian Aldrich-McKelvey Scaling in R via Stan","text":"may also useful inspect distribution scaled respondent positions self-placements. illustrates extent model transformed original data. example, impact models generally modest, although respondents detected flipped scale, thus self-placement flipped back.","code":"plot_over_self(list(fit_hbam, fit_hbam_mini), dat, \"chi\")"},{"path":"https://jbolstad.github.io/hbamr/articles/hbamr.html","id":"additional-parameters","dir":"Articles","previous_headings":"Plotting > Individual Parameters over Self-Placements","what":"Additional Parameters","title":"Hierarchical Bayesian Aldrich-McKelvey Scaling in R via Stan","text":"individual-level parameters like \"eta\" can also plotted passed hbam() via argument extra_pars fitting model. Parameters like \\(\\eta\\) stored hbam() results default, increase post-processing time well size model fits. (Note also homoskedastic models \"eta\" parameters “NF”-type models \"lambda\" \"kappa\" parameters.) estimated \\(\\eta\\) parameters yield information accuracy respondents’ answers. argument par = \"eta\" specified, plotting function display \\(\\sqrt{\\eta_i} / J\\), equals average error individual (mean \\(\\sigma_{ij}\\) \\(\\) across \\(j\\)). point estimates still calculated using posterior median, unless argument estimate = \"mean\" added.","code":"fit_hbam <- hbam(data = dat, extra_pars = \"eta\") plot_over_self(fit_hbam, dat, \"eta\")"},{"path":"https://jbolstad.github.io/hbamr/articles/hbamr.html","id":"posterior-summaries","dir":"Articles","previous_headings":"","what":"Posterior Summaries","title":"Hierarchical Bayesian Aldrich-McKelvey Scaling in R via Stan","text":"package also contains wrapper rstan::summary() called get_est(). function takes arguments object – stanfit object produced hbam() list produced fbam() – par – name parameter(s) summarized. function returns tibble, default contains posterior mean, 95% credible interval, posterior median, estimated number effective draws, split R-hat. One can obtain posterior quantiles using argument probs. get 50% credible interval (median), one add argument probs = c(0.25, 0.75). include Monte Carlo standard error posterior standard deviation, use argument simplify = FALSE. (applied outputs fbam(), get_est() returns point estimates.) posterior draws stimulus positions can summarized follows: equivalent call respondent positions :","code":"get_est(fit_hbam, \"theta\") ## # A tibble: 6 × 6 ##     mean `2.5%`  `50%` `97.5%` n_eff  Rhat ##    <dbl>  <dbl>  <dbl>   <dbl> <dbl> <dbl> ## 1 -1.02  -1.10  -1.02   -0.941 2160. 1.00  ## 2  1.62   1.55   1.62    1.68  2013. 1.00  ## 3 -1.68  -1.76  -1.68   -1.60  2473. 1.00  ## 4 -0.453 -0.574 -0.453  -0.333 3159. 1.00  ## 5  1.42   1.36   1.42    1.48  1912. 1.00  ## 6 -1.19  -1.25  -1.19   -1.13  2404. 0.999 get_est(fit_hbam, \"chi\") ## # A tibble: 643 × 6 ##       mean `2.5%`    `50%` `97.5%` n_eff  Rhat ##      <dbl>  <dbl>    <dbl>   <dbl> <dbl> <dbl> ##  1  0.965  -1.96   1.27      2.62  2862.  1.00 ##  2  1.21   -0.613  1.26      2.57  3421.  1.00 ##  3  1.39   -0.121  1.44      2.35  3212.  1.00 ##  4  0.0128 -1.80   0.00469   1.76  3745.  1.00 ##  5 -0.197  -2.04  -0.253     1.89  4089.  1.00 ##  6  1.45   -1.78   1.68      2.94  2336.  1.00 ##  7 -0.157  -1.15  -0.159     0.857 2975.  1.00 ##  8  0.943  -0.738  0.991     2.01  2924.  1.00 ##  9  0.587  -0.857  0.623     1.73  3691.  1.00 ## 10  0.125  -1.02   0.136     1.14  3654.  1.00 ## # ℹ 633 more rows"},{"path":"https://jbolstad.github.io/hbamr/articles/hbamr.html","id":"cross-validation","dir":"Articles","previous_headings":"","what":"Cross-Validation","title":"Hierarchical Bayesian Aldrich-McKelvey Scaling in R via Stan","text":"useful way compare alternative models estimate --sample prediction accuracy. specifically, can estimate expected log pointwise predictive density new data set (ELPD). straightforward stimuli placements, informative form basis estimating individual level parameters. similar analysis self-placement data generally possible, models require placements estimate corresponding latent respondent positions. section therefore focuses estimating ELPD stimulus placements. rstan loo packages contain functions estimating ELPDs performing approximate leave-one-(LOO) cross-validation using Pareto smoothed importance sampling (PSIS). However, PSIS-LOO works Pareto k values sufficiently low, number high values low moment matching can used problematic cases. practice, always case, rarely seems case BAM model. hbamr package therefore includes model codes functions perform K-fold cross-validation. function hbam_cv() similar hbam() takes arguments, perform K-fold cross-validation chosen model. contrast hbam(), default hbam_cv() allow respondents missing values (allow_miss = 0). reason cross-validation essentially creates missing values excluding data run. key choice performing cross-validation set K (number folds use), default package 10. function parallelized via parallel::mclapply() users non-Windows systems can specify higher number cores chains run chains different folds simultaneously. preserve memory, function extracts summaries log-likelihoods held-data drops stanfit objects done. memory requirements function therefore similar running single analysis one chain per core. function splits data K folds uses default seed produce folds time, unless different seed specified. perform 10-fold cross-validation selection models, run: Rather returning stanfit objects, function returns data frame containing estimated ELPD standard error. compare results across models, run: see unpooled BAM model worse predicting --sample data models, suggesting overfits data. HBAM_NF model – allow scale flipping – also performs worse, suggesting restrictive underfits. HBAM model outperforms two models case. also perform cross-validation model account heteroskedastic errors: estimated ELPD notably higher model compared heteroskedastic counterpart. suggest considerable degree heteroskedasticity data – surprising. Modeling heteroskedasticity increases prediction accuracy, noted necessarily translate much accurate estimates key model outputs. shown section plotting, results HBAM HBAM_MINI models similar. fact, estimated respondent positions correlate .97 .99, depending whether use posterior means medians. estimated stimulus positions also correlate .99, masks fact HBAM_MINI model places less well known candidate John B. Anderson left HBAM model . illustrates subtle differences users aware , even models tend produce similar results.","code":"elpd_hbam <- hbam_cv(self, stimuli, model = \"HBAM\", cores = 4) elpd_hbam_nf <- hbam_cv(self, stimuli, model = \"HBAM_NF\", cores = 4) elpd_bam <- hbam_cv(self, stimuli, model = \"BAM\", cores = 4) elpds <- rbind(elpd_bam, elpd_hbam, elpd_hbam_nf) elpds[order(elpds$ELPD), ] ##            ELPD   SE ## BAM     -5835.7 58.6 ## HBAM_NF -5766.9 51.2 ## HBAM    -5524.6 48.6 elpd_hbam_mini <- hbam_cv(self, stimuli, model = \"HBAM_MINI\", cores = 4) elpd_hbam_mini ##              ELPD   SE ## HBAM_MINI -5889.4 47.1"},{"path":"https://jbolstad.github.io/hbamr/articles/hbamr.html","id":"diagnostics","dir":"Articles","previous_headings":"","what":"Diagnostics","title":"Hierarchical Bayesian Aldrich-McKelvey Scaling in R via Stan","text":"rstan::sampling() function hbam() uses automatically performs number key diagnostic checks sampling issues warnings potential issue detected. authors rstan emphasize diagnostics careful model development, users rstan frequently encounter warnings users rjags. One warning users package may encounter Bulk Tail Effective Sample Size (ESS) low (see https://mc-stan.org/misc/warnings.html). straightforward solution issue increase number posterior draws, using iter argument. However, increases computational load, users consider carefully level accuracy need. hbam() function returns stanfit object, model fit can examined using full range diagnostic tools rstan package. Users consult rstan documentation details various diagnostic tests plots available. One example available tools traceplot():","code":"rstan::traceplot(fit_hbam, pars = \"theta\")"},{"path":"https://jbolstad.github.io/hbamr/articles/hbamr.html","id":"limits-to-exact-replication","dir":"Articles","previous_headings":"Diagnostics","what":"Limits to Exact Replication","title":"Hierarchical Bayesian Aldrich-McKelvey Scaling in R via Stan","text":"functions package accept seed argument operations involve random number generator. Supplying seed sufficient get exact results repeated runs system, ensure exact replication across systems software versions. Stan Reference Manual explains : Floating point operations modern computers notoriously difficult replicate fundamental arithmetic operations, right IEEE 754 encoding level, fully specified. primary problem precision operations varies across different hardware platforms software implementations. Stan designed allow full reproducibility. However, possible external constraints imposed floating point arithmetic. short, running functions package different systems likely yield slightly different results. noted, however, differences across systems minimal substantively negligible long user obtains sufficient number posterior draws.","code":""},{"path":[]},{"path":"https://jbolstad.github.io/hbamr/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Jørgen Bølstad. Author, maintainer.","code":""},{"path":"https://jbolstad.github.io/hbamr/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Bølstad J (2024). “Hierarchical Bayesian Aldrich–McKelvey Scaling.” Political Analysis, 32(1), 50–64. doi:10.1017/pan.2023.18. Bølstad J (2024). “hbamr: Hierarchical Bayesian Aldrich-McKelvey Scaling via Stan.” R package version 2.1.1, https://jbolstad.github.io/hbamr/.","code":"@Article{,   title = {Hierarchical {B}ayesian {A}ldrich–{M}c{K}elvey Scaling},   author = {Jørgen Bølstad},   journal = {Political Analysis},   year = {2024},   volume = {32},   number = {1},   pages = {50–64},   doi = {10.1017/pan.2023.18}, } @Misc{,   title = {{hbamr}: {H}ierarchical {B}ayesian {A}ldrich-{M}c{K}elvey Scaling via {S}tan},   author = {Jørgen Bølstad},   year = {2024},   note = {R package version 2.1.1},   url = {https://jbolstad.github.io/hbamr/}, }"},{"path":[]},{"path":"https://jbolstad.github.io/hbamr/index.html","id":"hierarchical-bayesian-aldrich-mckelvey-scaling","dir":"","previous_headings":"","what":"Hierarchical Bayesian Aldrich-McKelvey Scaling","title":"Hierarchical Bayesian Aldrich-McKelvey Scaling via Stan","text":"R package performing hierarchical Bayesian Aldrich-McKelvey (HBAM) scaling using Hamiltonian Monte Carlo simulations via Stan. Aldrich-McKelvey () scaling method estimating ideological positions survey respondents political actors common scale using positional survey data (Aldrich & McKelvey 1977). hierarchical versions model included package outperform versions terms yielding meaningful posterior distributions respondent positions terms recovering true respondent positions simulations (Bølstad 2024). package contains functions preparing data, fitting models, extracting estimates, plotting key results, comparing models using cross-validation.","code":""},{"path":"https://jbolstad.github.io/hbamr/index.html","id":"news","dir":"","previous_headings":"","what":"News","title":"Hierarchical Bayesian Aldrich-McKelvey Scaling via Stan","text":"Version 2.1.0: models now simulate errors respondents’ self-placements yield realistic levels uncertainty estimated respondent positions offering faster sampling. Version 2.0.1: New MULTI-type models explicitly model group-differences. Models FBAM-type now allow users specify key priors. models revised offer faster better sampling. See changelog comprehensive discussion updates.","code":""},{"path":"https://jbolstad.github.io/hbamr/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Hierarchical Bayesian Aldrich-McKelvey Scaling via Stan","text":"package available CRAN can installed using standard method: easiest fastest way install package, binaries CRAN include pre-compiled models ready use.","code":"install.packages(\"hbamr\")"},{"path":"https://jbolstad.github.io/hbamr/index.html","id":"vignette","dir":"","previous_headings":"","what":"Vignette","title":"Hierarchical Bayesian Aldrich-McKelvey Scaling via Stan","text":"vignette showing use key functions package available . can also viewed locally, installing package:","code":"vignette(\"hbamr\")"},{"path":"https://jbolstad.github.io/hbamr/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Hierarchical Bayesian Aldrich-McKelvey Scaling via Stan","text":"Load package: Load re-code example data: Fit standard HBAM model: Fit HBAM_MINI model: Plot estimated stimuli positions:  Plot distribution estimated respondent positions:  Plot estimated scale-stretching parameters respondents’ self-placements:","code":"library(\"hbamr\") data(LC1980) LC1980[LC1980 == 0 | LC1980 == 8 | LC1980 == 9] <- NA  self <- LC1980[, 1] stimuli <- LC1980[, -1] fit_hbam <- hbam(self, stimuli) fit_hbam_mini <- hbam(self, stimuli, model = \"HBAM_MINI\") plot_stimuli(fit_hbam) plot_respondents(fit_hbam) dat <- prep_data(self, stimuli) plot_over_self(list(fit_hbam, fit_hbam_mini), dat, \"abs_beta\")"},{"path":"https://jbolstad.github.io/hbamr/index.html","id":"references","dir":"","previous_headings":"","what":"References","title":"Hierarchical Bayesian Aldrich-McKelvey Scaling via Stan","text":"Aldrich, John H, Richard D McKelvey. 1977. “Method Scaling Applications 1968 1972 Presidential Elections.” American Political Science Review 71(1): 111-130. Bølstad, Jørgen. 2020. “Capturing Rationalization Bias Differential Item Functioning: Unified Bayesian Scaling Approach.” Political Analysis 28(3): 340-355. Bølstad, Jørgen. 2024. “Hierarchical Bayesian Aldrich-McKelvey Scaling.” Political Analysis 32(1): 50-64. Hare, Christopher et al. 2015. “Using Bayesian Aldrich-McKelvey Scaling Study Citizens’ Ideological Preferences Perceptions.” American Journal Political Science 59(3): 759-774.","code":""},{"path":"https://jbolstad.github.io/hbamr/reference/LC1980.html","id":null,"dir":"Reference","previous_headings":"","what":"1980 Liberal-Conservative Scales — LC1980","title":"1980 Liberal-Conservative Scales — LC1980","text":"Liberal-Conservative 7-point scales 1980 National Election Study. Includes (order) self-placement, rankings Carter, Reagan, Kennedy, Anderson, Republican party, Democratic Party. Stored matrix integers. numbers 0, 8, 9 considered missing values.","code":""},{"path":"https://jbolstad.github.io/hbamr/reference/LC1980.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"1980 Liberal-Conservative Scales — LC1980","text":"","code":"data(LC1980)"},{"path":"https://jbolstad.github.io/hbamr/reference/LC1980.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"1980 Liberal-Conservative Scales — LC1980","text":"object class matrix (inherits array) 888 rows 7 columns.","code":""},{"path":"https://jbolstad.github.io/hbamr/reference/LC1980.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"1980 Liberal-Conservative Scales — LC1980","text":"American National Election Studies: www.electionstudies.org/. dataset originally part basicspace package name (\"LC1980\").","code":""},{"path":"https://jbolstad.github.io/hbamr/reference/LC1980.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"1980 Liberal-Conservative Scales — LC1980","text":"","code":"data(LC1980) LC1980[LC1980 == 0 | LC1980 == 8 | LC1980 == 9] <- NA head(LC1980) #>    Self Carter Reagan Kennedy Anderson Republicans Democrats #> 1     6      2      6       1        7           5         5 #> 8     6      4      6       4        7           6         4 #> 9     6      3      6       3        3           6         2 #> 10    4      6      4       3        3           5         4 #> 11    5      7      2       5        5           7         5 #> 13    7      6      6       2        5           7         4"},{"path":"https://jbolstad.github.io/hbamr/reference/LC2012.html","id":null,"dir":"Reference","previous_headings":"","what":"2012 Liberal-Conservative Scales — LC2012","title":"2012 Liberal-Conservative Scales — LC2012","text":"Liberal-Conservative 7-point scales 2012 National Election Study. Includes (order) original case id, self-placement, rankings Obama, Romney, Democratic Party, Republican party. Missing values coded NA.","code":""},{"path":"https://jbolstad.github.io/hbamr/reference/LC2012.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"2012 Liberal-Conservative Scales — LC2012","text":"","code":"data(LC2012)"},{"path":"https://jbolstad.github.io/hbamr/reference/LC2012.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"2012 Liberal-Conservative Scales — LC2012","text":"object class data.frame 5914 rows 6 columns.","code":""},{"path":"https://jbolstad.github.io/hbamr/reference/LC2012.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"2012 Liberal-Conservative Scales — LC2012","text":"American National Election Studies: www.electionstudies.org/.","code":""},{"path":"https://jbolstad.github.io/hbamr/reference/LC2012.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"2012 Liberal-Conservative Scales — LC2012","text":"","code":"data(LC2012) head(LC2012) #>   caseid Self Obama Romney Democrats Republicans #> 1      1    1     1      7         1           7 #> 2      2    1     1      4         1           7 #> 3      3   NA    NA     NA        NA          NA #> 4      4   NA     7      4         6           4 #> 5      5    2     3      6         2           7 #> 6      6   NA    NA     NA        NA          NA"},{"path":"https://jbolstad.github.io/hbamr/reference/fbam.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit an FBAM model using optimization — fbam","title":"Fit an FBAM model using optimization — fbam","text":"Fit simplified Bayesian Aldrich-McKelvey model fixed hyperparameters using optimization via rstan. Users may replace default priors supplying values hyperparameters.","code":""},{"path":"https://jbolstad.github.io/hbamr/reference/fbam.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit an FBAM model using optimization — fbam","text":"","code":"fbam(   self = NULL,   stimuli = NULL,   model = \"FBAM_MINI\",   allow_miss = 2,   req_valid = NA,   req_unique = 2,   group_id = NULL,   data = NULL,   seed = sample.int(.Machine$integer.max, 1),   sigma_alpha = NULL,   sigma_beta = 0.35,   sigma_mu_alpha = NULL,   sigma_mu_beta = 0.3,   ... )"},{"path":"https://jbolstad.github.io/hbamr/reference/fbam.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit an FBAM model using optimization — fbam","text":"self numerical vector N ideological self-placements. missing data must coded NA. argument used data prepared advance via prep_data function. stimuli N × J matrix numerical stimulus placements, J number stimuli. missing data must coded NA. argument used data prepared advance via prep_data function. model Character: Name model used. Defaults FBAM_MINI. available options three models \"FBAM\" name. See documentation hbam() function descriptions models. allow_miss Integer specifying many missing stimulus positions accepted individual still included analysis. argument used data prepared advance via prep_data function. Defaults 2. req_valid Integer specifying many valid observations require respondent included analysis. default req_valid = J - allow_miss, specified, req_valid takes precedence. argument used data prepared advance via prep_data function. req_unique Integer specifying may unique positions ideological scale respondent required used placing stimuli order included analysis. default req_unique = 2. argument used data prepared advance via prep_data function. group_id Integer vector length N identifying group respondent belongs . supplied vector range 1 total number groups data, integers numbers represented supplied data. data required models \"MULTI\" name ignored fitting models. data List data prepared advance via prep_data function. required arguments self stimuli provided. seed positive integer specifying optional seed reproducibility. argument supplied, random seed generated function produce slightly different results run. sigma_alpha positive numeric value specifying standard deviation prior shift parameters FBAM_MINI model, standard deviation parameters' deviation group-means FBAM_MULTI models. (argument ignored HBAM models.) Defaults B / 4, B measures length survey scale number possible placements one side center. sigma_beta positive numeric value specifying standard deviation prior logged stretch parameters FBAM_MINI model, standard deviation logged parameters' deviation group-means FBAM_MULTI models. (argument ignored HBAM models.) Defaults .35. sigma_mu_alpha positive numeric value specifying standard deviation prior group-means shift parameters MULTI-type models. Defaults B / 5. sigma_mu_beta positive numeric value specifying standard deviation prior group-means logged stretch parameters MULTI-type models. Defaults .3. ... Arguments passed rstan::optimizing.","code":""},{"path":"https://jbolstad.github.io/hbamr/reference/fbam.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit an FBAM model using optimization — fbam","text":"list produced rstan::optimizing.","code":""},{"path":"https://jbolstad.github.io/hbamr/reference/fbam.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit an FBAM model using optimization — fbam","text":"","code":"# \\donttest{ # Loading ANES 2012 data: data(LC2012)  self <- LC2012[, 2] stimuli <- LC2012[, -c(1:2)]  # Fitting the FBAM_MINI model: fit_fbam_mini <- fbam(self, stimuli)  # Obtaining point estimates for the latent stimulus positions: theta_est <- get_est(fit_fbam_mini, par = \"theta\") # }"},{"path":"https://jbolstad.github.io/hbamr/reference/get_est.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract point estimates or other summaries of marginal posterior distributions — get_est","title":"Extract point estimates or other summaries of marginal posterior distributions — get_est","text":"objects produced hbam, function wrapper rstan::summary. objects produced fbam offers way extract point estimates.","code":""},{"path":"https://jbolstad.github.io/hbamr/reference/get_est.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract point estimates or other summaries of marginal posterior distributions — get_est","text":"","code":"get_est(   object,   par = \"theta\",   probs = c(0.025, 0.5, 0.975),   simplify = TRUE,   ... )"},{"path":"https://jbolstad.github.io/hbamr/reference/get_est.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract point estimates or other summaries of marginal posterior distributions — get_est","text":"object instance class stanfit produced hbam, list produced fbam. par Character: Name parameter type extracted. Typically \"theta\" (stimuli positions) \"chi\" (respondent positions). probs numeric vector quantiles interest summarizing stanfit objects. default c(0.025, 0.50, 0.975). simplify Logical: returned object simplified dropping Monte Carlo standard error posterior standard deviation? Defaults TRUE. ... arguments passed rstan::summary summarizing stanfit objects.","code":""},{"path":"https://jbolstad.github.io/hbamr/reference/get_est.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract point estimates or other summaries of marginal posterior distributions — get_est","text":"tibble containing summaries marginal posterior distributions. objects produced fbam, maximum posteriori estimates returned.","code":""},{"path":"https://jbolstad.github.io/hbamr/reference/get_plot_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract data for plotting results from an HBAM model. — get_plot_data","title":"Extract data for plotting results from an HBAM model. — get_plot_data","text":"Extract data plotting results HBAM model.","code":""},{"path":"https://jbolstad.github.io/hbamr/reference/get_plot_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract data for plotting results from an HBAM model. — get_plot_data","text":"","code":"get_plot_data(object, n_draws = 15, seed = 1)"},{"path":"https://jbolstad.github.io/hbamr/reference/get_plot_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract data for plotting results from an HBAM model. — get_plot_data","text":"object instance class stanfit produced hbam list produced fbam. n_draws Integer specifying number posterior draws use illustrating uncertainty population distribution. applies stanfit objects. seed positive integer specifying optional seed reproducibility. seed used select respondent position draws illustrating uncertainty. applies stanfit objects.","code":""},{"path":"https://jbolstad.github.io/hbamr/reference/get_plot_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract data for plotting results from an HBAM model. — get_plot_data","text":"list three tibbles: first element contains posterior mean stimulus positions, well x- y-values posterior modes (can useful labeling distributions). second element contains posterior draws stimulus positions (can used calculate marginal posterior densities). third element contains selected number posterior draws respondent (form key ingredient plot_respondents).","code":""},{"path":"https://jbolstad.github.io/hbamr/reference/hbam.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit an HBAM model — hbam","title":"Fit an HBAM model — hbam","text":"Fit Hierarchical Bayesian Aldrich-McKelvey model using automatically tuned Hamiltonian Monte Carlo sampling (NUTS) via rstan.","code":""},{"path":"https://jbolstad.github.io/hbamr/reference/hbam.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit an HBAM model — hbam","text":"","code":"hbam(   self = NULL,   stimuli = NULL,   model = \"HBAM\",   allow_miss = 2,   req_valid = NA,   req_unique = 2,   prefs = NULL,   group_id = NULL,   data = NULL,   pars = c(\"alpha\", \"beta\", \"chi\", \"lambda\", \"theta\"),   extra_pars = NULL,   include = TRUE,   chains = 4,   cores = parallel::detectCores(logical = FALSE),   warmup = 1000,   iter = 2000,   seed = sample.int(.Machine$integer.max, 1),   sigma_alpha = NULL,   sigma_beta = 0.35,   sigma_mu_alpha = NULL,   sigma_mu_beta = 0.3,   ... )"},{"path":"https://jbolstad.github.io/hbamr/reference/hbam.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit an HBAM model — hbam","text":"self numerical vector N ideological self-placements. missing data must coded NA. argument used data prepared advance via prep_data function. stimuli N × J matrix numerical stimulus placements, J number stimuli. missing data must coded NA. argument used data prepared advance via prep_data function. model Character: Name model used. Defaults HBAM. available models described Details. allow_miss Integer specifying many missing stimulus positions accepted individual still included analysis. argument used data prepared advance via prep_data function. Defaults 2. req_valid Integer specifying many valid observations require respondent included analysis. default req_valid = J - allow_miss, specified, req_valid takes precedence. argument used data prepared advance via prep_data function. req_unique Integer specifying may unique positions ideological scale respondent required used placing stimuli order included analysis. default req_unique = 2. argument used data prepared advance via prep_data function. prefs N × J matrix numerical stimulus ratings preference scores. data required HBAM_R HBAM_R_MINI models ignored fitting models. group_id Integer vector length N identifying group respondent belongs . supplied vector range 1 total number groups data, integers numbers represented supplied data. data required models \"MULTI\" name ignored fitting models. data List data prepared advance via prep_data function. required arguments self stimuli provided. pars vector character strings specifying parameters interest. include = TRUE, samples parameters named pars stored fitted results. Conversely, include = FALSE, samples parameters except named pars stored fitted results. default store results \"alpha\", \"beta\", \"chi\", \"lambda\", \"theta\". extra_pars vector character strings specifying parameters added pars. makes easy add one several additional parameters interest, without repeat default pars vector. default NULL. include Logical scalar defaulting TRUE indicating whether include exclude parameters given pars argument. FALSE, entire multidimensional parameters can excluded, rather particular elements . chains positive integer specifying number Markov chains. Defaults 4. cores number cores use executing Markov chains parallel. default, detected physical cores used chains equal higher number cores. warmup positive integer specifying number warmup (aka burn-) iterations per chain. step-size adaptation (default), also controls number iterations adaptation run (hence warmup samples used inference). number warmup iterations smaller iter. iter positive integer specifying number iterations chain (including warmup). seed positive integer specifying optional seed reproducibility. argument supplied, random seed generated function produce slightly different results run. sigma_alpha positive numeric value specifying standard deviation prior shift parameters FBAM_MINI model, standard deviation parameters' deviation group-means FBAM_MULTI models. (argument ignored HBAM models.) Defaults B / 4, B measures length survey scale number possible placements one side center. sigma_beta positive numeric value specifying standard deviation prior logged stretch parameters FBAM_MINI model, standard deviation logged parameters' deviation group-means FBAM_MULTI models. (argument ignored HBAM models.) Defaults .35. sigma_mu_alpha positive numeric value specifying standard deviation prior group-means shift parameters MULTI-type models. Defaults B / 5. sigma_mu_beta positive numeric value specifying standard deviation prior group-means logged stretch parameters MULTI-type models. Defaults .3. ... Arguments passed rstan::sampling.","code":""},{"path":"https://jbolstad.github.io/hbamr/reference/hbam.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit an HBAM model — hbam","text":"object S4 class stanfit.","code":""},{"path":"https://jbolstad.github.io/hbamr/reference/hbam.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit an HBAM model — hbam","text":"package provides several alternative models can selected using names . Users unsure model use advised use default HBAM model. speed sampling diagnostics issue, HBAM_MINI may provide useful alternative. HBAM default model, allows scale flipping employs hierarchical priors shift stretch parameters. also models heteroskedastic errors vary individual stimuli. Compared model Bølstad (2024), version slightly revised provide faster sampling. key difference original model respondent positions treated parameters, rather calculated function self-placements, individual-level parameters, simulated errors. makes model considerably faster, yielding similar results. model simulates errors self-placements magnitude respondent question places stimulus smallest errors. models package use approach. HBAM_MULTI version models differences groups defined user. requires integer vector identifying groups supplied argument group_id. model gives group separate hyperparameters locations prior distributions shift stretch parameters. Rather shrinking estimates toward mode whole dataset, model shrinks estimates toward mode group. vectors hyperparameters called mu_alpha mu_beta constructed means 0. scales priors hyperparameters can set user via arguments sigma_mu_alpha sigma_mu_beta. default values B / 5 .3, respectively. (, B measures length survey scale number possible placements one side center.) One potential use model supply self-placements (appropriately transformed) group_id, thus give self-placement group prior distribution shift stretch parameters. HBAM_NF (formerly HBAM_0) version HBAM model allow scale flipping. may useful truly zero cases scale flipping data. scenarios can created artificially, may also arise real data. example, expert surveys appear unlikely contain many instances scale flipping. data contain zero cases flipping, models allow flipping contain superfluous parameters lead inefficient sampling. Models allow flipping sample faster typically yield slightly accurate estimates. models therefore preferable flipping present. HBAM_MULTI_NF version HBAM_MULTI model allow scale flipping. HBAM_MINI version HBAM model assumes prediction errors stimuli placements homoskedastic. model tends sample faster faster standard HBAM model yielding similar point estimates. large datasets, model may provide reasonable compromise model complexity estimation speed. FBAM_MINI version HBAM_MINI model fixed hyperparameters allow fitting via optimization rather MCMC -- can useful large data sets. model allows user specify scales priors shift (logged) stretch parameters via arguments sigma_alpha sigma_beta. default values B / 4 .35, respectively. defaults intended realistic weakly informative. Users want control degree shrinkage individual-level parameters may find useful fit model -- FBAM models -- via either MCMC optimization. FBAM_MULTI version FBAM_MINI model shares group-modeling features HBAM_MULTI model. allows user set scales priors shift stretch parameters via arguments sigma_alpha sigma_beta, set scales priors mu_alpha mu_beta via arguments sigma_mu_alpha sigma_mu_beta. FBAM_MULTI_NF version FBAM_MULTI model allow scale flipping. HBAM_R_MINI version HBAM_MINI model incorporates rationalization component ISR model Bølstad (2020). model requires additional data supplied argument pref: N × J matrix stimuli ratings respondents. rationalization part model simplified relative original ISR model: direction respondents move disfavored stimuli estimated common expectation possible self-placement scale. BAM unpooled model wide uniform priors shift stretch parameters. similar JAGS version introduced Hare et al. (2015). model mainly provided offer baseline model comparisons. simple fast, model tends overfit data produce invalid posterior distributions respondent positions (see Bølstad 2024). HBAM_2 deprecated replaced general HBAM_MULTI model. models can also used situations self-placements available goal estimate stimulus positions. can achieved supplying vector zeros (random data) instead real self-placements: self = rep(0, nrow(stimuli)). See hbamr vignette table summarizing key characteristics available models. see code models, use show_code() function.","code":""},{"path":"https://jbolstad.github.io/hbamr/reference/hbam.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fit an HBAM model — hbam","text":"Bølstad, Jørgen (2024). Hierarchical Bayesian Aldrich-McKelvey Scaling. Political Analysis. 32(1): 50–64. doi:10.1017/pan.2023.18 . Bølstad, Jørgen (2020). Capturing Rationalization Bias Differential Item Functioning: Unified Bayesian Scaling Approach. Political Analysis 28(3): 340–355. Hare, Christopher et al. (2015). Using Bayesian Aldrich-McKelvey Scaling Study Citizens' Ideological Preferences Perceptions. American Journal Political Science 59(3): 759–774.","code":""},{"path":"https://jbolstad.github.io/hbamr/reference/hbam.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit an HBAM model — hbam","text":"","code":"# \\donttest{ # Loading and re-coding ANES 1980 data: data(LC1980) LC1980[LC1980 == 0 | LC1980 == 8 | LC1980 == 9] <- NA  # Making a small subset of the data for illustration: self <- LC1980[1:100, 1] stimuli <- LC1980[1:100, -1]  # Fitting the HBAM_MINI model, obtaining 1000 draws: fit_hbam_mini <- hbam(self, stimuli, model = \"HBAM_MINI\",                    warmup = 500, iter = 1000, chains = 2) #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess  # Preparing the data before fitting, requiring complete responses: dat <- prep_data(self, stimuli, allow_miss = 0) fit_hbam_mini <- hbam(data = dat, model = \"HBAM_MINI\",                    warmup = 500, iter = 1000, chains = 2) #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess  # Obtaining posterior summaries for the latent stimulus positions: theta_est <- get_est(fit_hbam_mini, par = \"theta\")  # Fitting the FBAM_MULTI_NF model with self-placements as group_id:   # Note: This works because the self-placements in this case are positive integers. fit_fbam_multi_nf <- hbam(self, stimuli, group_id = self, model = \"FBAM_MULTI_NF\",                        warmup = 500, iter = 1000, chains = 2) # }"},{"path":"https://jbolstad.github.io/hbamr/reference/hbam_cv.html","id":null,"dir":"Reference","previous_headings":"","what":"Perform K-fold cross-validation — hbam_cv","title":"Perform K-fold cross-validation — hbam_cv","text":"function performs K-fold cross-validation HBAM FBAM model order estimate expected log pointwise predictive density new dataset (ELPD).","code":""},{"path":"https://jbolstad.github.io/hbamr/reference/hbam_cv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perform K-fold cross-validation — hbam_cv","text":"","code":"hbam_cv(   self = NULL,   stimuli = NULL,   model = \"HBAM\",   allow_miss = 0,   req_valid = NA,   req_unique = 2,   prefs = NULL,   group_id = NULL,   prep_data = TRUE,   data = NULL,   K = 10,   chains = 2,   cores = 1,   warmup = 1000,   iter = 3000,   thin = 1,   seed = 1,   sigma_alpha = NULL,   sigma_beta = 0.35,   sigma_mu_alpha = NULL,   sigma_mu_beta = 0.3,   ... )"},{"path":"https://jbolstad.github.io/hbamr/reference/hbam_cv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perform K-fold cross-validation — hbam_cv","text":"self numerical vector N ideological self-placements. missing data must coded NA. argument used data prepared advance via prep_data function. stimuli N × J matrix numerical stimulus placements, J number stimuli. missing data must coded NA. argument used data prepared advance via prep_data function. model Character: Name model used. Defaults HBAM. allow_miss Integer specifying many missing stimulus positions accepted individual still included analysis. argument used data prepared advance via prep_data function. Defaults 0. req_valid Integer specifying many valid observations require respondent included analysis. default req_valid = J - allow_miss, specified, req_valid takes precedence. argument used data prepared advance via prep_data function. req_unique Integer specifying may unique positions ideological scale respondent required used placing stimuli order included analysis. default req_unique = 2. argument used data prepared advance via prep_data function. prefs N × J matrix numerical stimulus ratings preference scores. data required HBAM_R HBAM_R_MINI models ignored fitting models. group_id Integer vector length N identifying group respondent belongs . supplied vector range 1 total number groups data, integers numbers represented supplied data. data required models \"MULTI\" name ignored fitting models. prep_data Logical: data prepared fitting model? (data prepared advance first running prep_data prep_data_cv functions)? , set prep_data = FALSE.) Defaults prep_data = TRUE. data list data produced prep_data followed prep_data_cv. K integer 2, specifying number folds use analysis. Defaults 10. chains positive integer specifying number Markov chains use model fit. Defaults 2. cores number cores use executing Markov chains parallel. Defaults 1 parallelization works non-Windows machines. systems, user set cores equal number physical cores. Specifying higher number cores chains run chains different folds simultaneously save time. warmup positive integer specifying number warmup (aka burn-) iterations per chain. step-size adaptation (default), also controls number iterations adaptation run (hence warmup samples used inference). number warmup iterations smaller iter. iter positive integer specifying number iterations chain (including warmup). thin positive integer specifying period saving samples. seed integer passed set.seed creating folds increase reproducibility comparability. Defaults 1 applies fold-creation argument prep_data TRUE. supplied seed argument also used generate seeds sampling algorithm. sigma_alpha positive numeric value specifying standard deviation prior shift parameters FBAM_MINI model, standard deviation parameters' deviation group-means FBAM_MULTI models. (argument ignored HBAM models.) Defaults B / 4, B measures length survey scale number possible placements one side center. sigma_beta positive numeric value specifying standard deviation prior logged stretch parameters FBAM_MINI model, standard deviation logged parameters' deviation group-means FBAM_MULTI models. (argument ignored HBAM models.) Defaults .35. sigma_mu_alpha positive numeric value specifying standard deviation prior group-means shift parameters MULTI-type models. Defaults B / 5. sigma_mu_beta positive numeric value specifying standard deviation prior group-means logged stretch parameters MULTI-type models. Defaults .3. ... Arguments passed rstan::sampling.","code":""},{"path":"https://jbolstad.github.io/hbamr/reference/hbam_cv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Perform K-fold cross-validation — hbam_cv","text":"data frame containing estimated ELPD standard error.","code":""},{"path":"https://jbolstad.github.io/hbamr/reference/hbam_cv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Perform K-fold cross-validation — hbam_cv","text":"","code":"# \\donttest{ # Loading and re-coding ANES 1980 data: data(LC1980) LC1980[LC1980 == 0 | LC1980 == 8 | LC1980 == 9] <- NA  # Making a small subset of the data for illustration: self <- LC1980[1:50, 1] stimuli <- LC1980[1:50, -1]  # Performing 10-fold cross-validation for the HBAM_MINI model:   # NOTE: You normally want to use ALL physical cores for this, not just 1. cv_hbam_mini <- hbam_cv(self, stimuli, model = \"HBAM_MINI\",                         chains = 1, cores = 1, warmup = 500, iter = 1000) #>  #> SAMPLING FOR MODEL 'HBAM_MINI' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 0.000216 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 2.16 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:   1 / 1000 [  0%]  (Warmup) #> Chain 1: Iteration: 100 / 1000 [ 10%]  (Warmup) #> Chain 1: Iteration: 200 / 1000 [ 20%]  (Warmup) #> Chain 1: Iteration: 300 / 1000 [ 30%]  (Warmup) #> Chain 1: Iteration: 400 / 1000 [ 40%]  (Warmup) #> Chain 1: Iteration: 500 / 1000 [ 50%]  (Warmup) #> Chain 1: Iteration: 501 / 1000 [ 50%]  (Sampling) #> Chain 1: Iteration: 600 / 1000 [ 60%]  (Sampling) #> Chain 1: Iteration: 700 / 1000 [ 70%]  (Sampling) #> Chain 1: Iteration: 800 / 1000 [ 80%]  (Sampling) #> Chain 1: Iteration: 900 / 1000 [ 90%]  (Sampling) #> Chain 1: Iteration: 1000 / 1000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 3.596 seconds (Warm-up) #> Chain 1:                1.402 seconds (Sampling) #> Chain 1:                4.998 seconds (Total) #> Chain 1:  #>  #> SAMPLING FOR MODEL 'HBAM_MINI' NOW (CHAIN 2). #> Chain 2:  #> Chain 2: Gradient evaluation took 0.000178 seconds #> Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 1.78 seconds. #> Chain 2: Adjust your expectations accordingly! #> Chain 2:  #> Chain 2:  #> Chain 2: Iteration:   1 / 1000 [  0%]  (Warmup) #> Chain 2: Iteration: 100 / 1000 [ 10%]  (Warmup) #> Chain 2: Iteration: 200 / 1000 [ 20%]  (Warmup) #> Chain 2: Iteration: 300 / 1000 [ 30%]  (Warmup) #> Chain 2: Iteration: 400 / 1000 [ 40%]  (Warmup) #> Chain 2: Iteration: 500 / 1000 [ 50%]  (Warmup) #> Chain 2: Iteration: 501 / 1000 [ 50%]  (Sampling) #> Chain 2: Iteration: 600 / 1000 [ 60%]  (Sampling) #> Chain 2: Iteration: 700 / 1000 [ 70%]  (Sampling) #> Chain 2: Iteration: 800 / 1000 [ 80%]  (Sampling) #> Chain 2: Iteration: 900 / 1000 [ 90%]  (Sampling) #> Chain 2: Iteration: 1000 / 1000 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 3.486 seconds (Warm-up) #> Chain 2:                1.318 seconds (Sampling) #> Chain 2:                4.804 seconds (Total) #> Chain 2:  #>  #> SAMPLING FOR MODEL 'HBAM_MINI' NOW (CHAIN 3). #> Chain 3:  #> Chain 3: Gradient evaluation took 0.000175 seconds #> Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 1.75 seconds. #> Chain 3: Adjust your expectations accordingly! #> Chain 3:  #> Chain 3:  #> Chain 3: Iteration:   1 / 1000 [  0%]  (Warmup) #> Chain 3: Iteration: 100 / 1000 [ 10%]  (Warmup) #> Chain 3: Iteration: 200 / 1000 [ 20%]  (Warmup) #> Chain 3: Iteration: 300 / 1000 [ 30%]  (Warmup) #> Chain 3: Iteration: 400 / 1000 [ 40%]  (Warmup) #> Chain 3: Iteration: 500 / 1000 [ 50%]  (Warmup) #> Chain 3: Iteration: 501 / 1000 [ 50%]  (Sampling) #> Chain 3: Iteration: 600 / 1000 [ 60%]  (Sampling) #> Chain 3: Iteration: 700 / 1000 [ 70%]  (Sampling) #> Chain 3: Iteration: 800 / 1000 [ 80%]  (Sampling) #> Chain 3: Iteration: 900 / 1000 [ 90%]  (Sampling) #> Chain 3: Iteration: 1000 / 1000 [100%]  (Sampling) #> Chain 3:  #> Chain 3:  Elapsed Time: 3.715 seconds (Warm-up) #> Chain 3:                1.316 seconds (Sampling) #> Chain 3:                5.031 seconds (Total) #> Chain 3:  #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #>  #> SAMPLING FOR MODEL 'HBAM_MINI' NOW (CHAIN 4). #> Chain 4:  #> Chain 4: Gradient evaluation took 0.000174 seconds #> Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 1.74 seconds. #> Chain 4: Adjust your expectations accordingly! #> Chain 4:  #> Chain 4:  #> Chain 4: Iteration:   1 / 1000 [  0%]  (Warmup) #> Chain 4: Iteration: 100 / 1000 [ 10%]  (Warmup) #> Chain 4: Iteration: 200 / 1000 [ 20%]  (Warmup) #> Chain 4: Iteration: 300 / 1000 [ 30%]  (Warmup) #> Chain 4: Iteration: 400 / 1000 [ 40%]  (Warmup) #> Chain 4: Iteration: 500 / 1000 [ 50%]  (Warmup) #> Chain 4: Iteration: 501 / 1000 [ 50%]  (Sampling) #> Chain 4: Iteration: 600 / 1000 [ 60%]  (Sampling) #> Chain 4: Iteration: 700 / 1000 [ 70%]  (Sampling) #> Chain 4: Iteration: 800 / 1000 [ 80%]  (Sampling) #> Chain 4: Iteration: 900 / 1000 [ 90%]  (Sampling) #> Chain 4: Iteration: 1000 / 1000 [100%]  (Sampling) #> Chain 4:  #> Chain 4:  Elapsed Time: 3.873 seconds (Warm-up) #> Chain 4:                1.322 seconds (Sampling) #> Chain 4:                5.195 seconds (Total) #> Chain 4:  #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #>  #> SAMPLING FOR MODEL 'HBAM_MINI' NOW (CHAIN 5). #> Chain 5:  #> Chain 5: Gradient evaluation took 0.000193 seconds #> Chain 5: 1000 transitions using 10 leapfrog steps per transition would take 1.93 seconds. #> Chain 5: Adjust your expectations accordingly! #> Chain 5:  #> Chain 5:  #> Chain 5: Iteration:   1 / 1000 [  0%]  (Warmup) #> Chain 5: Iteration: 100 / 1000 [ 10%]  (Warmup) #> Chain 5: Iteration: 200 / 1000 [ 20%]  (Warmup) #> Chain 5: Iteration: 300 / 1000 [ 30%]  (Warmup) #> Chain 5: Iteration: 400 / 1000 [ 40%]  (Warmup) #> Chain 5: Iteration: 500 / 1000 [ 50%]  (Warmup) #> Chain 5: Iteration: 501 / 1000 [ 50%]  (Sampling) #> Chain 5: Iteration: 600 / 1000 [ 60%]  (Sampling) #> Chain 5: Iteration: 700 / 1000 [ 70%]  (Sampling) #> Chain 5: Iteration: 800 / 1000 [ 80%]  (Sampling) #> Chain 5: Iteration: 900 / 1000 [ 90%]  (Sampling) #> Chain 5: Iteration: 1000 / 1000 [100%]  (Sampling) #> Chain 5:  #> Chain 5:  Elapsed Time: 3.462 seconds (Warm-up) #> Chain 5:                2.227 seconds (Sampling) #> Chain 5:                5.689 seconds (Total) #> Chain 5:  #>  #> SAMPLING FOR MODEL 'HBAM_MINI' NOW (CHAIN 6). #> Chain 6:  #> Chain 6: Gradient evaluation took 0.000173 seconds #> Chain 6: 1000 transitions using 10 leapfrog steps per transition would take 1.73 seconds. #> Chain 6: Adjust your expectations accordingly! #> Chain 6:  #> Chain 6:  #> Chain 6: Iteration:   1 / 1000 [  0%]  (Warmup) #> Chain 6: Iteration: 100 / 1000 [ 10%]  (Warmup) #> Chain 6: Iteration: 200 / 1000 [ 20%]  (Warmup) #> Chain 6: Iteration: 300 / 1000 [ 30%]  (Warmup) #> Chain 6: Iteration: 400 / 1000 [ 40%]  (Warmup) #> Chain 6: Iteration: 500 / 1000 [ 50%]  (Warmup) #> Chain 6: Iteration: 501 / 1000 [ 50%]  (Sampling) #> Chain 6: Iteration: 600 / 1000 [ 60%]  (Sampling) #> Chain 6: Iteration: 700 / 1000 [ 70%]  (Sampling) #> Chain 6: Iteration: 800 / 1000 [ 80%]  (Sampling) #> Chain 6: Iteration: 900 / 1000 [ 90%]  (Sampling) #> Chain 6: Iteration: 1000 / 1000 [100%]  (Sampling) #> Chain 6:  #> Chain 6:  Elapsed Time: 3.753 seconds (Warm-up) #> Chain 6:                1.311 seconds (Sampling) #> Chain 6:                5.064 seconds (Total) #> Chain 6:  #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess #>  #> SAMPLING FOR MODEL 'HBAM_MINI' NOW (CHAIN 7). #> Chain 7:  #> Chain 7: Gradient evaluation took 0.000174 seconds #> Chain 7: 1000 transitions using 10 leapfrog steps per transition would take 1.74 seconds. #> Chain 7: Adjust your expectations accordingly! #> Chain 7:  #> Chain 7:  #> Chain 7: Iteration:   1 / 1000 [  0%]  (Warmup) #> Chain 7: Iteration: 100 / 1000 [ 10%]  (Warmup) #> Chain 7: Iteration: 200 / 1000 [ 20%]  (Warmup) #> Chain 7: Iteration: 300 / 1000 [ 30%]  (Warmup) #> Chain 7: Iteration: 400 / 1000 [ 40%]  (Warmup) #> Chain 7: Iteration: 500 / 1000 [ 50%]  (Warmup) #> Chain 7: Iteration: 501 / 1000 [ 50%]  (Sampling) #> Chain 7: Iteration: 600 / 1000 [ 60%]  (Sampling) #> Chain 7: Iteration: 700 / 1000 [ 70%]  (Sampling) #> Chain 7: Iteration: 800 / 1000 [ 80%]  (Sampling) #> Chain 7: Iteration: 900 / 1000 [ 90%]  (Sampling) #> Chain 7: Iteration: 1000 / 1000 [100%]  (Sampling) #> Chain 7:  #> Chain 7:  Elapsed Time: 3.728 seconds (Warm-up) #> Chain 7:                1.329 seconds (Sampling) #> Chain 7:                5.057 seconds (Total) #> Chain 7:  #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #>  #> SAMPLING FOR MODEL 'HBAM_MINI' NOW (CHAIN 8). #> Chain 8:  #> Chain 8: Gradient evaluation took 0.000175 seconds #> Chain 8: 1000 transitions using 10 leapfrog steps per transition would take 1.75 seconds. #> Chain 8: Adjust your expectations accordingly! #> Chain 8:  #> Chain 8:  #> Chain 8: Iteration:   1 / 1000 [  0%]  (Warmup) #> Chain 8: Iteration: 100 / 1000 [ 10%]  (Warmup) #> Chain 8: Iteration: 200 / 1000 [ 20%]  (Warmup) #> Chain 8: Iteration: 300 / 1000 [ 30%]  (Warmup) #> Chain 8: Iteration: 400 / 1000 [ 40%]  (Warmup) #> Chain 8: Iteration: 500 / 1000 [ 50%]  (Warmup) #> Chain 8: Iteration: 501 / 1000 [ 50%]  (Sampling) #> Chain 8: Iteration: 600 / 1000 [ 60%]  (Sampling) #> Chain 8: Iteration: 700 / 1000 [ 70%]  (Sampling) #> Chain 8: Iteration: 800 / 1000 [ 80%]  (Sampling) #> Chain 8: Iteration: 900 / 1000 [ 90%]  (Sampling) #> Chain 8: Iteration: 1000 / 1000 [100%]  (Sampling) #> Chain 8:  #> Chain 8:  Elapsed Time: 3.658 seconds (Warm-up) #> Chain 8:                1.316 seconds (Sampling) #> Chain 8:                4.974 seconds (Total) #> Chain 8:  #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #>  #> SAMPLING FOR MODEL 'HBAM_MINI' NOW (CHAIN 9). #> Chain 9:  #> Chain 9: Gradient evaluation took 0.000175 seconds #> Chain 9: 1000 transitions using 10 leapfrog steps per transition would take 1.75 seconds. #> Chain 9: Adjust your expectations accordingly! #> Chain 9:  #> Chain 9:  #> Chain 9: Iteration:   1 / 1000 [  0%]  (Warmup) #> Chain 9: Iteration: 100 / 1000 [ 10%]  (Warmup) #> Chain 9: Iteration: 200 / 1000 [ 20%]  (Warmup) #> Chain 9: Iteration: 300 / 1000 [ 30%]  (Warmup) #> Chain 9: Iteration: 400 / 1000 [ 40%]  (Warmup) #> Chain 9: Iteration: 500 / 1000 [ 50%]  (Warmup) #> Chain 9: Iteration: 501 / 1000 [ 50%]  (Sampling) #> Chain 9: Iteration: 600 / 1000 [ 60%]  (Sampling) #> Chain 9: Iteration: 700 / 1000 [ 70%]  (Sampling) #> Chain 9: Iteration: 800 / 1000 [ 80%]  (Sampling) #> Chain 9: Iteration: 900 / 1000 [ 90%]  (Sampling) #> Chain 9: Iteration: 1000 / 1000 [100%]  (Sampling) #> Chain 9:  #> Chain 9:  Elapsed Time: 3.557 seconds (Warm-up) #> Chain 9:                1.316 seconds (Sampling) #> Chain 9:                4.873 seconds (Total) #> Chain 9:  #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #>  #> SAMPLING FOR MODEL 'HBAM_MINI' NOW (CHAIN 10). #> Chain 10:  #> Chain 10: Gradient evaluation took 0.000174 seconds #> Chain 10: 1000 transitions using 10 leapfrog steps per transition would take 1.74 seconds. #> Chain 10: Adjust your expectations accordingly! #> Chain 10:  #> Chain 10:  #> Chain 10: Iteration:   1 / 1000 [  0%]  (Warmup) #> Chain 10: Iteration: 100 / 1000 [ 10%]  (Warmup) #> Chain 10: Iteration: 200 / 1000 [ 20%]  (Warmup) #> Chain 10: Iteration: 300 / 1000 [ 30%]  (Warmup) #> Chain 10: Iteration: 400 / 1000 [ 40%]  (Warmup) #> Chain 10: Iteration: 500 / 1000 [ 50%]  (Warmup) #> Chain 10: Iteration: 501 / 1000 [ 50%]  (Sampling) #> Chain 10: Iteration: 600 / 1000 [ 60%]  (Sampling) #> Chain 10: Iteration: 700 / 1000 [ 70%]  (Sampling) #> Chain 10: Iteration: 800 / 1000 [ 80%]  (Sampling) #> Chain 10: Iteration: 900 / 1000 [ 90%]  (Sampling) #> Chain 10: Iteration: 1000 / 1000 [100%]  (Sampling) #> Chain 10:  #> Chain 10:  Elapsed Time: 3.571 seconds (Warm-up) #> Chain 10:                1.314 seconds (Sampling) #> Chain 10:                4.885 seconds (Total) #> Chain 10:  #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess cv_hbam_mini #>             ELPD SE #> HBAM_MINI -375.9 14 # }"},{"path":"https://jbolstad.github.io/hbamr/reference/hbamr-package.html","id":null,"dir":"Reference","previous_headings":"","what":"Hierarchical Bayesian Aldrich-McKelvey Scaling via Stan — hbamr-package","title":"Hierarchical Bayesian Aldrich-McKelvey Scaling via Stan — hbamr-package","text":"Fit hierarchical Bayesian Aldrich-McKelvey (HBAM) models using form Hamiltonian Monte Carlo via Stan. Aldrich-McKelvey () scaling method estimating ideological positions survey respondents political actors common scale using positional survey data. hierarchical versions Bayesian model included package outperform versions terms yielding meaningful posterior distributions respondent positions terms recovering true respondent positions simulations. package contains functions preparing data, fitting models, extracting estimates, plotting key results, comparing models using cross-validation.","code":""},{"path":"https://jbolstad.github.io/hbamr/reference/hbamr-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Hierarchical Bayesian Aldrich-McKelvey Scaling via Stan — hbamr-package","text":"Bølstad, Jørgen (2024). Hierarchical Bayesian Aldrich-McKelvey Scaling. Political Analysis. 32(1): 50–64. doi:10.1017/pan.2023.18 . Stan Development Team (2024). RStan: R interface Stan. R package version 2.32.5. https://mc-stan.org.","code":""},{"path":[]},{"path":"https://jbolstad.github.io/hbamr/reference/hbamr-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Hierarchical Bayesian Aldrich-McKelvey Scaling via Stan — hbamr-package","text":"Jørgen Bølstad","code":""},{"path":"https://jbolstad.github.io/hbamr/reference/plot_over_self.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot individual parameter estimates over self-placements — plot_over_self","title":"Plot individual parameter estimates over self-placements — plot_over_self","text":"Create boxplot individual parameter estimates HBAM model self-placements","code":""},{"path":"https://jbolstad.github.io/hbamr/reference/plot_over_self.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot individual parameter estimates over self-placements — plot_over_self","text":"","code":"plot_over_self(   object,   data,   par = \"chi\",   estimate = \"median\",   names = NULL,   parlabel = NULL,   fill = \"#2166AC\",   color = \"#053061\",   width = 0.7,   alpha = 0.5,   outlier.size = 0.3,   median_color = \"black\",   median_lwd = 0.7 )"},{"path":"https://jbolstad.github.io/hbamr/reference/plot_over_self.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot individual parameter estimates over self-placements — plot_over_self","text":"object object class stanfit produced hbam, list produced fbam, list objects, produce faceted plot. data list data used produce object(s). par Character: Name parameter plotted. One following: \"alpha\", \"beta\", \"abs_beta\", \"lambda\", \"chi\". Defaults \"chi\". individual-level parameters like \"eta\" can specified passed hbam() via argument extra_pars fitting model. (Note homoskedastic models \"eta\" parameters \"NF\"-type models \"lambda\" \"kappa\" parameters.) estimate Character: Specifying type posterior point estimate use. One \"median\" \"mean\". Defaults \"median\". applies stanfit objects. names optional character vector model names length supplied list models. parlabel optional character containing alternative label parameter (parsed passed expression). fill Fill color boxes. Passed geom_boxplot. color Color outer lines. Passed geom_boxplot. width Width boxes. Passed geom_boxplot. alpha Number [0,1]: Inverse level transparency fill color. Passed geom_boxplot. outlier.size Size dots representing outliers. Passed geom_boxplot. median_color Color solid line representing median. median_lwd Thickness solid line representing median.","code":""},{"path":"https://jbolstad.github.io/hbamr/reference/plot_over_self.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot individual parameter estimates over self-placements — plot_over_self","text":"ggplot object.","code":""},{"path":"https://jbolstad.github.io/hbamr/reference/plot_respondents.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot estimated respondent positions — plot_respondents","title":"Plot estimated respondent positions — plot_respondents","text":"Plot distribution estimated respondent positions HBAM model.","code":""},{"path":"https://jbolstad.github.io/hbamr/reference/plot_respondents.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot estimated respondent positions — plot_respondents","text":"","code":"plot_respondents(   object,   inc_stimuli = TRUE,   n_draws = 15,   color = \"#053061\",   fill = \"#2166AC\",   alpha_color = 0.6,   alpha_fill = 0.7/n_draws,   seed = 1 )"},{"path":"https://jbolstad.github.io/hbamr/reference/plot_respondents.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot estimated respondent positions — plot_respondents","text":"object instance class stanfit produced hbam. inc_stimuli Logical: estimated stimulus positions also shown? n_draws Integer specifying number posterior draws use illustrating uncertainty population distribution. Defaults 15. color Color lines illustrating uncertainty. fill Fill color density plots. alpha_color Number [0,1]: Inverse level transparency line color. alpha_fill Number [0,1]: Inverse level transparency fill color. seed positive integer specifying optional seed reproducibility. seed used select respondent position draws illustrating uncertainty.","code":""},{"path":"https://jbolstad.github.io/hbamr/reference/plot_respondents.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot estimated respondent positions — plot_respondents","text":"ggplot object.","code":""},{"path":"https://jbolstad.github.io/hbamr/reference/plot_stimuli.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot estimated stimulus positions — plot_stimuli","title":"Plot estimated stimulus positions — plot_stimuli","text":"Plot marginal posterior distributions stimulus positions HBAM model","code":""},{"path":"https://jbolstad.github.io/hbamr/reference/plot_stimuli.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot estimated stimulus positions — plot_stimuli","text":"","code":"plot_stimuli(object, rev_color = FALSE, alpha = 0.55)"},{"path":"https://jbolstad.github.io/hbamr/reference/plot_stimuli.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot estimated stimulus positions — plot_stimuli","text":"object instance class stanfit produced hbam. rev_color Logical: Display low positions red high positions blue. alpha Number [0,1]: Inverse level transparency fill color.","code":""},{"path":"https://jbolstad.github.io/hbamr/reference/plot_stimuli.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot estimated stimulus positions — plot_stimuli","text":"ggplot object.","code":""},{"path":"https://jbolstad.github.io/hbamr/reference/prep_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare data to fit an HBAM model — prep_data","title":"Prepare data to fit an HBAM model — prep_data","text":"function prepares data fit hierarchical Bayesian Aldrich-McKelvey (HBAM) model. can run ahead fitting models, can run implicitly part single function call fit models using hbam. applies set inclusion criteria, performs necessary data transformation, returns list data suited sampling rstan. data provided prep_data can centered, : function detect un-centered data attempt center automatically, assuming highest lowest observed values data mark extremes scale.","code":""},{"path":"https://jbolstad.github.io/hbamr/reference/prep_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare data to fit an HBAM model — prep_data","text":"","code":"prep_data(   self,   stimuli,   prefs = NULL,   allow_miss = 2,   req_valid = NA,   req_unique = 2,   B = NULL,   group_id = NULL )"},{"path":"https://jbolstad.github.io/hbamr/reference/prep_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare data to fit an HBAM model — prep_data","text":"self numerical vector N ideological self-placements. missing data must coded NA. stimuli N × J matrix numerical stimulus placements, J number stimuli. missing data must coded NA. prefs N × J matrix numerical stimulus ratings preference scores. data required \"HBAM_R\" \"HBAM_R_MINI\" models ignored fitting models. allow_miss Integer specifying many missing stimulus positions accepted individual still included analysis. argument used data prepared advance via prep_data function. Defaults 2. req_valid Integer specifying many valid observations require respondent included analysis. default req_valid = J - allow_miss, specified, req_valid takes precedence. req_unique Integer specifying may unique positions ideological scale respondent required used placing stimuli order included analysis. default req_unique = 2. B Integer specifying upper bound survey scale centering. supplied, information inferred data. group_id Integer vector length N identifying group respondent belongs . supplied id-variable range 1 total number groups data, integers numbers represented supplied data. data required models \"MULTI\" name ignored fitting models.","code":""},{"path":"https://jbolstad.github.io/hbamr/reference/prep_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare data to fit an HBAM model — prep_data","text":"list data used hbam. returned list includes logical vector keep, identifies rows original data kept analysis. stimuli data stored vector long-form sparse matrix. stimuli data include column-names, preserved later use.","code":""},{"path":"https://jbolstad.github.io/hbamr/reference/prep_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prepare data to fit an HBAM model — prep_data","text":"","code":"# Loading and re-coding ANES 1980 data: data(LC1980) LC1980[LC1980 == 0 | LC1980 == 8 | LC1980 == 9] <- NA self <- LC1980[, 1] stimuli <- LC1980[, -1]  # Prepare data for model fitting, using defaults: dat <- prep_data(self, stimuli)  # Prepare data for model fitting, using using alternative settings: dat2 <- prep_data(self, stimuli, allow_miss = 0, req_unique = 3)  # Obtain the data that are included in the analysis: self2 <- self[dat2$keep] stimuli2 <- stimuli[dat2$keep, ]"},{"path":"https://jbolstad.github.io/hbamr/reference/prep_data_cv.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare data for a K-fold cross-validation of an HBAM model — prep_data_cv","title":"Prepare data for a K-fold cross-validation of an HBAM model — prep_data_cv","text":"function turns data prepared hbam list K versions, version includes different vector identifying holdout-data.","code":""},{"path":"https://jbolstad.github.io/hbamr/reference/prep_data_cv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare data for a K-fold cross-validation of an HBAM model — prep_data_cv","text":"","code":"prep_data_cv(data, K = 10, seed = 1)"},{"path":"https://jbolstad.github.io/hbamr/reference/prep_data_cv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare data for a K-fold cross-validation of an HBAM model — prep_data_cv","text":"data list data produced prep_data. K integer 2, specifying number folds use analysis. Defaults 10. seed integer passed set.seed creating folds increase reproducibility. Defaults 1.","code":""},{"path":"https://jbolstad.github.io/hbamr/reference/prep_data_cv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare data for a K-fold cross-validation of an HBAM model — prep_data_cv","text":"list K data objects version includes different vector identifying holdout-data.","code":""},{"path":"https://jbolstad.github.io/hbamr/reference/prep_data_cv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prepare data for a K-fold cross-validation of an HBAM model — prep_data_cv","text":"","code":"# Loading and re-coding ANES 1980 data: data(LC1980) LC1980[LC1980 == 0 | LC1980 == 8 | LC1980 == 9] <- NA self <- LC1980[, 1] stimuli <- LC1980[, -1] dat <- prep_data(self, stimuli)  # Prepare data for cross-validation: dat_cv <- prep_data_cv(dat, K = 10)"},{"path":"https://jbolstad.github.io/hbamr/reference/show_code.html","id":null,"dir":"Reference","previous_headings":"","what":"Show the code for an HBAM or FBAM model — show_code","title":"Show the code for an HBAM or FBAM model — show_code","text":"Show Stan code one models package.","code":""},{"path":"https://jbolstad.github.io/hbamr/reference/show_code.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Show the code for an HBAM or FBAM model — show_code","text":"","code":"show_code(model = NULL)"},{"path":"https://jbolstad.github.io/hbamr/reference/show_code.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Show the code for an HBAM or FBAM model — show_code","text":"model Character: Name model. See documentation hbam() function list available models.","code":""},{"path":"https://jbolstad.github.io/hbamr/reference/show_code.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Show the code for an HBAM or FBAM model — show_code","text":"function prints Stan code.","code":""},{"path":"https://jbolstad.github.io/hbamr/reference/show_code.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Show the code for an HBAM or FBAM model — show_code","text":"","code":"show_code(\"HBAM\") #> S4 class stanmodel 'HBAM' coded as follows: #> data { #>   int<lower = 1> N;                       // n of individuals #>   int<lower = 1> J;                       // n of items #>   int<lower = 1> N_obs;                   // n of observations #>   array[N_obs] int<lower = 1> ii;         // index i in matrix #>   array[N_obs] int<lower = 1> jj;         // index j in matrix #>   int<lower = 1> B;                       // length of scale -1 / 2 #>   int<lower = 1, upper = J> L;            // left pole #>   int<lower = 1, upper = J> R;            // right pole #>   array[N_obs] int<lower = -B, upper = B> Y; // reported stimuli positions #>   vector<lower = -B, upper = B>[N] V;     // reported self-placements #>   int<lower = 0, upper = 1> CV;           // indicator of cross-validation #>   array[N_obs] int<lower = 0, upper = 1> holdout; // holdout for cross-validation #> } #> transformed data { #>   real<lower = 0> sigma_alpha_prior_rate = (2 - 1) / (B / 5.0); #>   real<lower = 0> tau_prior_rate = (2 - 1) / (B / 5.0); #> } #> parameters { #>   matrix[N, 2] alpha_raw;                 // shift parameter, split, raw #>   matrix[N, 2] beta_raw;                  // stretch parameter, split, raw #>   ordered[2] theta_lr;                    // left and right pole #>   array[J] real theta_raw;                // remaining stimuli #>   real<lower = 0> sigma_alpha;            // sd of alpha #>   real<lower = 0, upper = 2> sigma_beta;  // sd of log(beta) #>   real<lower = 3, upper = 30> nu;         // concentration of etas #>   real<lower = 0> tau;                    // scale of errors #>   vector<lower = 0>[N] eta;               // mean ind. error variance x J^2 #>   simplex[J] rho;                         // stimuli-shares of variance #>   vector[N] logit_lambda;                 // raw mixing proportion, flipping #>   real<lower = 0> psi;                    // mean of prior on logit of lambda #> } #> transformed parameters { #>   array[J] real theta;                    // latent stimuli position #>   matrix[N, 2] alpha0;                    // shift parameter, split #>   matrix[N, 2] beta0;                     // stretch parameter, split #>   vector[N_obs] log_lik;                  // pointwise log-likelihood for Y #>   vector<lower = 0, upper = 1>[N] lambda = inv_logit(psi + logit_lambda * 3); // prob. of non-flipping #>   real<lower = 0> eta_scale = tau * J; #>   theta = theta_raw; #>   theta[L] = theta_lr[1];                 // safeguard to ensure identification #>   theta[R] = theta_lr[2]; #>   alpha0[, 1] = alpha_raw[, 1] * sigma_alpha; // non-centered specifications #>   alpha0[, 2] = alpha_raw[, 2] * sigma_alpha; #>   beta0[, 1] = exp(beta_raw[, 1] * sigma_beta); #>   beta0[, 2] = -exp(beta_raw[, 2] * sigma_beta); #>   for (n in 1:N_obs) { #>     log_lik[n] = log_mix( lambda[ii[n]], #>       normal_lpdf(Y[n] | alpha0[ii[n], 1] + beta0[ii[n], 1] * theta[jj[n]], #>         sqrt(eta[ii[n]]) * rho[jj[n]]), #>       normal_lpdf(Y[n] | alpha0[ii[n], 2] + beta0[ii[n], 2] * theta[jj[n]], #>         sqrt(eta[ii[n]]) * rho[jj[n]]) ); #>   } #> } #> model { #>   theta_raw ~ normal(0, B); #>   theta_lr ~ normal(0, B); #>   alpha_raw[, 1] ~ normal(0, 1); #>   alpha_raw[, 2] ~ normal(0, 1); #>   sigma_alpha ~ gamma(2, sigma_alpha_prior_rate); #>   beta_raw[, 1] ~ normal(0, 1); #>   beta_raw[, 2] ~ normal(0, 1); #>   sigma_beta ~ gamma(3, 10); #>   eta ~ scaled_inv_chi_square(nu, eta_scale); #>   nu ~ gamma(25, 2.5); #>   tau ~ gamma(2, tau_prior_rate); #>   rho ~ dirichlet(rep_vector(5, J)); #>   logit_lambda ~ normal(0, 1); #>   psi ~ lognormal(1.4, .5); #>   if(CV == 0) #>     target += sum(log_lik); #>   else #>     for (n in 1:N_obs) { #>       if(holdout[n] == 0) #>         target += log_lik[n]; #>     } #> } #> generated quantities { #>   matrix[N, 2] chi0;                      // latent respondent positions, split #>   vector[N] chi;                          // latent respondent positions, combined #>   real<lower = 0> min_rho = min(rho); #>   vector[N] kappa = to_vector(bernoulli_rng(lambda)); #>   vector[N] alpha = (kappa .* alpha0[, 1]) + ((1 - kappa) .* alpha0[, 2]); #>   vector[N] beta = (kappa .* beta0[, 1]) + ((1 - kappa) .* beta0[, 2]); #>   vector[N] V_error = to_vector(normal_rng(0, sqrt(eta) * min_rho)); #>   chi0[, 1] = ((V - V_error - alpha0[, 1]) ./ beta0[, 1]); #>   chi0[, 2] = ((V - V_error - alpha0[, 2]) ./ beta0[, 2]); #>   chi = (kappa .* chi0[, 1]) + ((1 - kappa) .* chi0[, 2]); #> }"},{"path":"https://jbolstad.github.io/hbamr/news/index.html","id":"hbamr-210","dir":"Changelog","previous_headings":"","what":"hbamr 2.1.0","title":"hbamr 2.1.0","text":"CRAN release: 2024-01-17","code":""},{"path":"https://jbolstad.github.io/hbamr/news/index.html","id":"revisions-to-existing-models-2-1-0","dir":"Changelog","previous_headings":"","what":"Revisions to existing models","title":"hbamr 2.1.0","text":"models package now simulate errors respondents’ self-placements. original HBAM model, respondents’ latent positions treated parameters, several consequences: yielded realistic level uncertainty estimated positions, also led slower sampling. Furthermore, hierarchical prior latent respondent positions shrunk toward zero, undesirable applications affected distances respondents stimuli. Finally, original approach led nuanced posterior distribution combinations individual-level parameter values lead implausible values respondent positions weighted . However, model’s log-normal prior stretch parameters sufficient yield meaningful respondent positions estimates, significant cost treating latent respondent positions parameters. current versions model instead simulate errors self-placements yield level uncertainty original model, sampling considerably faster.","code":""},{"path":"https://jbolstad.github.io/hbamr/news/index.html","id":"deprecated-models-2-1-0","dir":"Changelog","previous_headings":"","what":"Deprecated models","title":"hbamr 2.1.0","text":"HBAM_MAX removed offered little extra models revised simulate errors respondents’ self-placements.","code":""},{"path":"https://jbolstad.github.io/hbamr/news/index.html","id":"hbamr-201","dir":"Changelog","previous_headings":"","what":"hbamr 2.0.1","title":"hbamr 2.0.1","text":"CRAN release: 2024-01-08","code":""},{"path":"https://jbolstad.github.io/hbamr/news/index.html","id":"new-function-2-0-1","dir":"Changelog","previous_headings":"","what":"New function","title":"hbamr 2.0.1","text":"show_code() shows Stan code model package.","code":""},{"path":"https://jbolstad.github.io/hbamr/news/index.html","id":"new-models-2-0-1","dir":"Changelog","previous_headings":"","what":"New models","title":"hbamr 2.0.1","text":"HBAM_MULTI version models differences groups defined user. requires integer vector identifying groups supplied argument group_id. model gives group separate hyperparameters locations prior distributions shift stretch parameters. Rather shrinking estimates toward mode whole dataset, model shrinks estimates toward mode group. vectors hyperparameters called mu_alpha mu_beta constructed means 0. scales priors hyperparameters can set user via arguments sigma_mu_alpha sigma_mu_beta. One potential use model supply self-placements (appropriately transformed) group_id, thus give self-placement group prior distribution shift stretch parameters. HBAM_MULTI_NF version HBAM_MULTI model allow scale flipping. FBAM_MULTI version FBAM_MINI model shares group-modeling features HBAM_MULTI model. allows user set scales priors shift stretch parameters via arguments sigma_alpha sigma_beta, set scales priors mu_alpha mu_beta via arguments sigma_mu_alpha sigma_mu_beta. FBAM_MULTI_NF version FBAM_MULTI model allow scale flipping.","code":""},{"path":"https://jbolstad.github.io/hbamr/news/index.html","id":"renamed-models-2-0-1","dir":"Changelog","previous_headings":"","what":"Renamed models","title":"hbamr 2.0.1","text":"original HBAM model renamed HBAM_MAX. HBAM_NE model renamed HBAM makes better default model. HBAM_0 renamed HBAM_NF. consistent models offer faster sampling, model longer models latent respondent positions parameters.","code":""},{"path":"https://jbolstad.github.io/hbamr/news/index.html","id":"revisions-to-existing-models-2-0-1","dir":"Changelog","previous_headings":"","what":"Revisions to existing models","title":"hbamr 2.0.1","text":"FBAM_MINI (well new FBAM models) now allows user-defined prior distributions. models (except HBAM_MAX) revised treat respondent positions parameters. results considerably faster sampling. HBAM models allow scale flipping given logit-normal prior mixing proportions, lambda (.e. expectations latent discrete flipping parameters, kappa). replaces original beta prior, trigger divergent transitions.","code":""},{"path":"https://jbolstad.github.io/hbamr/news/index.html","id":"deprecated-models-2-0-1","dir":"Changelog","previous_headings":"","what":"Deprecated models","title":"hbamr 2.0.1","text":"HBAM_2 replaced general HBAM_MULTI model. HBAM_HM removed offered little extra number models kept somewhat limited. HBAM_R removed users typically better simpler HBAM_R_MINI.","code":""}]
