<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="description" content="Fit a Hierarchical Bayesian Aldrich-McKelvey model using automatically tuned Hamiltonian Monte Carlo sampling (NUTS) via rstan."><title>Fit an HBAM model — hbam • hbamr</title><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous"><!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Fit an HBAM model — hbam"><meta property="og:description" content="Fit a Hierarchical Bayesian Aldrich-McKelvey model using automatically tuned Hamiltonian Monte Carlo sampling (NUTS) via rstan."><!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">hbamr</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">2.1.0</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="nav-item">
  <a class="nav-link" href="../articles/hbamr.html">Get started</a>
</li>
<li class="active nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../news/index.html">Changelog</a>
</li>
      </ul><form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off"></form>

      <ul class="navbar-nav"><li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/jbolstad/hbamr/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul></div>

    
  </div>
</nav><div class="container template-reference-topic">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Fit an HBAM model</h1>
      <small class="dont-index">Source: <a href="https://github.com/jbolstad/hbamr/blob/HEAD/R/hbam.R" class="external-link"><code>R/hbam.R</code></a></small>
      <div class="d-none name"><code>hbam.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p>Fit a Hierarchical Bayesian Aldrich-McKelvey model using automatically tuned Hamiltonian Monte Carlo sampling (NUTS) via <code>rstan</code>.</p>
    </div>

    <div class="section level2">
    <h2 id="ref-usage">Usage<a class="anchor" aria-label="anchor" href="#ref-usage"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">hbam</span><span class="op">(</span></span>
<span>  self <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  stimuli <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  model <span class="op">=</span> <span class="st">"HBAM"</span>,</span>
<span>  allow_miss <span class="op">=</span> <span class="fl">2</span>,</span>
<span>  req_valid <span class="op">=</span> <span class="cn">NA</span>,</span>
<span>  req_unique <span class="op">=</span> <span class="fl">2</span>,</span>
<span>  prefs <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  group_id <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  data <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  pars <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"alpha"</span>, <span class="st">"beta"</span>, <span class="st">"chi"</span>, <span class="st">"lambda"</span>, <span class="st">"theta"</span><span class="op">)</span>,</span>
<span>  extra_pars <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  include <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  chains <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  cores <span class="op">=</span> <span class="fu">parallel</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/r/parallel/detectCores.html" class="external-link">detectCores</a></span><span class="op">(</span>logical <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>,</span>
<span>  warmup <span class="op">=</span> <span class="fl">1000</span>,</span>
<span>  iter <span class="op">=</span> <span class="fl">2000</span>,</span>
<span>  seed <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html" class="external-link">sample.int</a></span><span class="op">(</span><span class="va">.Machine</span><span class="op">$</span><span class="va">integer.max</span>, <span class="fl">1</span><span class="op">)</span>,</span>
<span>  sigma_alpha <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  sigma_beta <span class="op">=</span> <span class="fl">0.35</span>,</span>
<span>  sigma_mu_alpha <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  sigma_mu_beta <span class="op">=</span> <span class="fl">0.3</span>,</span>
<span>  <span class="va">...</span></span>
<span><span class="op">)</span></span></code></pre></div>
    </div>

    <div class="section level2">
    <h2 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a></h2>
    <dl><dt>self</dt>
<dd><p>A numerical vector of N ideological self-placements. Any missing data must be coded as NA. This argument will not be used if the data have been prepared in advance via the <code>prep_data</code> function.</p></dd>


<dt>stimuli</dt>
<dd><p>An N × J matrix of numerical stimulus placements, where J is the number of stimuli. Any missing data must be coded as NA. This argument will not be used if the data have been prepared in advance via the <code>prep_data</code> function.</p></dd>


<dt>model</dt>
<dd><p>Character: Name of the model to be used. Defaults to HBAM. The available models are described under Details.</p></dd>


<dt>allow_miss</dt>
<dd><p>Integer specifying how many missing stimulus positions to be accepted for an individual still to be included in the analysis. This argument will not be used if the data have been prepared in advance via the <code>prep_data</code> function. Defaults to 2.</p></dd>


<dt>req_valid</dt>
<dd><p>Integer specifying how many valid observations to require for a respondent to be included in the analysis. The default is <code>req_valid = J - allow_miss</code>, but if specified, <code>req_valid</code> takes precedence. This argument will not be used if the data have been prepared in advance via the <code>prep_data</code> function.</p></dd>


<dt>req_unique</dt>
<dd><p>Integer specifying how may unique positions on the ideological scale each respondent is required to have used when placing the stimuli in order to be included in the analysis. The default is <code>req_unique = 2</code>. This argument will not be used if the data have been prepared in advance via the <code>prep_data</code> function.</p></dd>


<dt>prefs</dt>
<dd><p>An N × J matrix of numerical stimulus ratings or preference scores. These data are only required by the HBAM_R and HBAM_R_MINI models and will be ignored when fitting other models.</p></dd>


<dt>group_id</dt>
<dd><p>Integer vector of length N identifying which group each respondent belongs to. The supplied vector should range from 1 to the total number of groups in the data, and all integers between these numbers should be represented in the supplied data. These data are only required by models with "MULTI" in their name and will be ignored when fitting other models.</p></dd>


<dt>data</dt>
<dd><p>List of data that have been prepared in advance via the <code>prep_data</code> function. Not required if the arguments <code>self</code> and <code>stimuli</code> are provided.</p></dd>


<dt>pars</dt>
<dd><p>A vector of character strings specifying parameters of interest. If <code>include = TRUE</code>, only samples for parameters named in pars are stored in the fitted results. Conversely, if <code>include = FALSE</code>, samples for all parameters except those named in pars are stored in the fitted results. The default is to store results for "alpha", "beta", "chi", "lambda", and "theta".</p></dd>


<dt>extra_pars</dt>
<dd><p>A vector of character strings specifying parameters to be added to <code>pars</code>. This makes it easy to add one or several additional parameters of interest, without having to repeat the default <code>pars</code> vector. The default is <code>NULL</code>.</p></dd>


<dt>include</dt>
<dd><p>Logical scalar defaulting to <code>TRUE</code> indicating whether to include or exclude the parameters given by the pars argument. If <code>FALSE</code>, only entire multidimensional parameters can be excluded, rather than particular elements of them.</p></dd>


<dt>chains</dt>
<dd><p>A positive integer specifying the number of Markov chains. Defaults to 4.</p></dd>


<dt>cores</dt>
<dd><p>The number of cores to use when executing the Markov chains in parallel. By default, all detected physical cores will be used if <code>chains</code> is equal to or higher than the number of cores.</p></dd>


<dt>warmup</dt>
<dd><p>A positive integer specifying the number of warmup (aka burn-in) iterations per chain. If step-size adaptation is on (which it is by default), this also controls the number of iterations for which adaptation is run (and hence these warmup samples should not be used for inference). The number of warmup iterations should be smaller than <code>iter</code>.</p></dd>


<dt>iter</dt>
<dd><p>A positive integer specifying the number of iterations for each chain (including warmup).</p></dd>


<dt>seed</dt>
<dd><p>A positive integer specifying an optional seed for reproducibility. If this argument is not supplied, a random seed will be generated and the function will produce slightly different results on each run.</p></dd>


<dt>sigma_alpha</dt>
<dd><p>A positive numeric value specifying the standard deviation of the prior on the shift parameters in the FBAM_MINI model, or the standard deviation of the parameters' deviation from the group-means in FBAM_MULTI models. (This argument will be ignored by HBAM models.) Defaults to B / 4, where B measures the length of the survey scale as the number of possible placements on one side of the center.</p></dd>


<dt>sigma_beta</dt>
<dd><p>A positive numeric value specifying the standard deviation of the prior on the logged stretch parameters in the FBAM_MINI model, or the standard deviation of the logged parameters' deviation from the group-means in FBAM_MULTI models. (This argument will be ignored by HBAM models.) Defaults to .35.</p></dd>


<dt>sigma_mu_alpha</dt>
<dd><p>A positive numeric value specifying the standard deviation of the prior on the group-means of the shift parameters in MULTI-type models. Defaults to B / 5.</p></dd>


<dt>sigma_mu_beta</dt>
<dd><p>A positive numeric value specifying the standard deviation of the prior on the group-means of the logged stretch parameters in MULTI-type models. Defaults to .3.</p></dd>


<dt>...</dt>
<dd><p>Arguments passed to <code><a href="https://mc-stan.org/rstan/reference/stanmodel-method-sampling.html" class="external-link">rstan::sampling</a></code>.</p></dd>

</dl></div>
    <div class="section level2">
    <h2 id="value">Value<a class="anchor" aria-label="anchor" href="#value"></a></h2>
    

<p>An object of S4 class <code>stanfit</code>.</p>
    </div>
    <div class="section level2">
    <h2 id="details">Details<a class="anchor" aria-label="anchor" href="#details"></a></h2>
    <p>This package provides several alternative models that can be selected using the names below. Users who are unsure which model to use are advised to use the default HBAM model. If speed or sampling diagnostics are an issue, HBAM_MINI may provide a useful alternative.</p>
<p><strong>HBAM</strong> is the default model, which allows for scale flipping and employs hierarchical priors on the shift and stretch parameters. It also models heteroskedastic errors that vary by both individual and stimuli. Compared to the model in Bølstad (2024), this version has been slightly revised to provide faster sampling. A key difference from the original model is that the respondent positions are not treated as parameters, but rather calculated as a function of self-placements, individual-level parameters, and simulated errors. This makes the model considerably faster, while yielding very similar results. The model simulates errors in the self-placements of the same magnitude as that with which the respondent in question places the stimulus with the smallest errors. All models in the package use this approach.</p>
<p><strong>HBAM_MULTI</strong> is a version that models differences between groups defined by the user. It requires an integer vector identifying the groups to be supplied as the argument <code>group_id</code>. The model gives each group separate hyperparameters for the locations of the prior distributions for the shift and stretch parameters. Rather than shrinking the estimates toward the mode for the whole dataset, this model shrinks the estimates toward the mode for the group. The vectors of hyperparameters are called <code>mu_alpha</code> and <code>mu_beta</code> and are constructed to have means of 0. The scales of the priors on these hyperparameters can be set by the user via the arguments <code>sigma_mu_alpha</code> and <code>sigma_mu_beta</code>. The default values are B / 5 and .3, respectively. (Here, B measures the length of the survey scale as the number of possible placements on one side of the center.) One potential use for this model is to supply self-placements (appropriately transformed) as <code>group_id</code>, and thus give each self-placement group its own prior distribution for the shift and stretch parameters.</p>
<p><strong>HBAM_NF</strong> (formerly HBAM_0) is a version of the HBAM model that does not allow for scale flipping. This may be useful if there are truly zero cases of scale flipping in the data. Such scenarios can be created artificially, but may also arise in real data. For example, expert surveys appear unlikely to contain many instances of scale flipping. For data that contain zero cases of flipping, models that allow for flipping contain superfluous parameters that lead to inefficient sampling. Models that do not allow for flipping will sample faster and typically yield slightly more accurate estimates. Such models are therefore preferable when no flipping is present.</p>
<p><strong>HBAM_MULTI_NF</strong> is a version of the HBAM_MULTI model that does not allow for scale flipping.</p>
<p><strong>HBAM_MINI</strong> is a version of the HBAM model that assumes the prediction errors in the stimuli placements to be homoskedastic. This model tends to sample faster faster than the standard HBAM model while yielding very similar point estimates. For large datasets, this model may provide a reasonable compromise between model complexity and estimation speed.</p>
<p><strong>FBAM_MINI</strong> is a version of the HBAM_MINI model with fixed hyperparameters to allow fitting via optimization rather than MCMC -- which can be useful for large data sets. This model allows the user to specify the scales of the priors for the shift and (logged) stretch parameters via the arguments <code>sigma_alpha</code> and <code>sigma_beta</code>. The default values are B / 4 and .35, respectively. These defaults are intended to be realistic and weakly informative. As with the other models, the default values of the scale-dependent priors are automatically adjusted to the length of the survey scale. Users who want to control the degree of shrinkage of the individual-level parameters may find it useful to fit this model (or other FBAM models) via either MCMC or optimization.</p>
<p><strong>FBAM_MULTI</strong> is a version of the FBAM_MINI model that shares the group-modeling features of the HBAM_MULTI model. It allows the user to set the scales of the priors for the shift and stretch parameters via the arguments <code>sigma_alpha</code> and <code>sigma_beta</code>, and set the scales of the priors on <code>mu_alpha</code> and <code>mu_beta</code> via the arguments <code>sigma_mu_alpha</code> and <code>sigma_mu_beta</code>.</p>
<p><strong>FBAM_MULTI_NF</strong> is a version of the FBAM_MULTI model that does not allow for scale flipping.</p>
<p><strong>HBAM_R_MINI</strong> is a version of the HBAM_MINI model that incorporates the rationalization component of the ISR model by Bølstad (2020). This model requires additional data to be supplied as the argument <code>pref</code>: An N × J matrix of stimuli ratings from the respondents. The rationalization part of the model is simplified relative to the original ISR model: The direction in which respondents move disfavored stimuli is estimated as a common expectation for each possible self-placement on the scale.</p>
<p><strong>BAM</strong> is an unpooled model with wide uniform priors on the shift and stretch parameters. It is similar to the JAGS version introduced by Hare et al. (2015). This model is mainly provided to offer a baseline for model comparisons. While it is simple and fast, this model tends to overfit the data and produce invalid posterior distributions for some respondent positions (see Bølstad 2024).</p>
<p><strong>HBAM_2</strong> is deprecated and replaced by the more general HBAM_MULTI model.</p>
<p>These models can also be used in situations where self-placements are not available and the only goal is to estimate stimulus positions. This can be achieved by supplying a vector of zeros (or random data) instead of real self-placements: <code>self = rep(0, nrow(stimuli))</code>.</p>
<p>See the <code>hbamr</code> vignette for a table summarizing the key characteristics of the available models.</p>
<p>To see the code for any of the models, use the <code><a href="show_code.html">show_code()</a></code> function.</p>
    </div>
    <div class="section level2">
    <h2 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a></h2>
    
<ul><li><p>Bølstad, Jørgen (2024). Hierarchical Bayesian Aldrich-McKelvey Scaling. <em>Political Analysis</em>. 32(1): 50–64. <a href="https://doi.org/10.1017/pan.2023.18" class="external-link">doi:10.1017/pan.2023.18</a>
.</p></li>
<li><p>Bølstad, Jørgen (2020). Capturing Rationalization Bias and Differential Item Functioning: A Unified Bayesian Scaling Approach. <em>Political Analysis</em> 28(3): 340–355.</p></li>
<li><p>Hare, Christopher et al. (2015). Using Bayesian Aldrich-McKelvey Scaling to Study Citizens' Ideological Preferences and Perceptions. <em>American Journal of Political Science</em> 59(3): 759–774.</p></li>
</ul></div>

    <div class="section level2">
    <h2 id="ref-examples">Examples<a class="anchor" aria-label="anchor" href="#ref-examples"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span><span class="co"># \donttest{</span></span></span>
<span class="r-in"><span><span class="co"># Loading and re-coding ANES 1980 data:</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="va">LC1980</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">LC1980</span><span class="op">[</span><span class="va">LC1980</span> <span class="op">==</span> <span class="fl">0</span> <span class="op">|</span> <span class="va">LC1980</span> <span class="op">==</span> <span class="fl">8</span> <span class="op">|</span> <span class="va">LC1980</span> <span class="op">==</span> <span class="fl">9</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="cn">NA</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Making a small subset of the data for illustration:</span></span></span>
<span class="r-in"><span><span class="va">self</span> <span class="op">&lt;-</span> <span class="va">LC1980</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">100</span>, <span class="fl">1</span><span class="op">]</span></span></span>
<span class="r-in"><span><span class="va">stimuli</span> <span class="op">&lt;-</span> <span class="va">LC1980</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">100</span>, <span class="op">-</span><span class="fl">1</span><span class="op">]</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Fitting the HBAM_MINI model, obtaining 1000 draws:</span></span></span>
<span class="r-in"><span><span class="va">fit_hbam_mini</span> <span class="op">&lt;-</span> <span class="fu">hbam</span><span class="op">(</span><span class="va">self</span>, <span class="va">stimuli</span>, model <span class="op">=</span> <span class="st">"HBAM_MINI"</span>,</span></span>
<span class="r-in"><span>                   warmup <span class="op">=</span> <span class="fl">500</span>, iter <span class="op">=</span> <span class="fl">1000</span>, chains <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Preparing the data before fitting, requiring complete responses:</span></span></span>
<span class="r-in"><span><span class="va">dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="prep_data.html">prep_data</a></span><span class="op">(</span><span class="va">self</span>, <span class="va">stimuli</span>, allow_miss <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">fit_hbam_mini</span> <span class="op">&lt;-</span> <span class="fu">hbam</span><span class="op">(</span>data <span class="op">=</span> <span class="va">dat</span>, model <span class="op">=</span> <span class="st">"HBAM_MINI"</span>,</span></span>
<span class="r-in"><span>                   warmup <span class="op">=</span> <span class="fl">500</span>, iter <span class="op">=</span> <span class="fl">1000</span>, chains <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span></span>
<span class="r-wrn co"><span class="r-pr">#&gt;</span> <span class="warning">Warning: </span>Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable.</span>
<span class="r-wrn co"><span class="r-pr">#&gt;</span> Running the chains for more iterations may help. See</span>
<span class="r-wrn co"><span class="r-pr">#&gt;</span> https://mc-stan.org/misc/warnings.html#bulk-ess</span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Obtaining posterior summaries for the latent stimulus positions:</span></span></span>
<span class="r-in"><span><span class="va">theta_est</span> <span class="op">&lt;-</span> <span class="fu"><a href="get_est.html">get_est</a></span><span class="op">(</span><span class="va">fit_hbam_mini</span>, par <span class="op">=</span> <span class="st">"theta"</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Fitting the FBAM_MULTI_NF model with self-placements as group_id:</span></span></span>
<span class="r-in"><span>  <span class="co"># Note: This works because the self-placements in this case are positive integers.</span></span></span>
<span class="r-in"><span><span class="va">fit_fbam_multi_nf</span> <span class="op">&lt;-</span> <span class="fu">hbam</span><span class="op">(</span><span class="va">self</span>, <span class="va">stimuli</span>, group_id <span class="op">=</span> <span class="va">self</span>, model <span class="op">=</span> <span class="st">"FBAM_MULTI_NF"</span>,</span></span>
<span class="r-in"><span>                       warmup <span class="op">=</span> <span class="fl">500</span>, iter <span class="op">=</span> <span class="fl">1000</span>, chains <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> SAMPLING FOR MODEL 'FBAM_MULTI_NF' NOW (CHAIN 1).</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Chain 1: Unrecoverable error evaluating the log probability at the initial value.</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Chain 1: Exception: mismatch in number dimensions declared and found in context; processing stage=parameter initialization; variable name=mu_alpha_raw; dims declared=(7); dims found=(1,7) (in 'FBAM_MULTI_NF', line 31, column 2 to column 26)</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Error : Exception: mismatch in number dimensions declared and found in context; processing stage=parameter initialization; variable name=mu_alpha_raw; dims declared=(7); dims found=(1,7) (in 'FBAM_MULTI_NF', line 31, column 2 to column 26)</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> character(0)</span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> error occurred during calling the sampler; sampling not done</span>
<span class="r-in"><span><span class="co"># }</span></span></span>
</code></pre></div>
    </div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p></p><p>Developed by Jørgen Bølstad.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p><p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer></div>

  

  

  </body></html>

